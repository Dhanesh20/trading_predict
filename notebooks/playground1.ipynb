{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column Name       | Definition                                           |\n",
    "|-------------------|-----------------------------------------------------|\n",
    "| SYMBOL            | Stock symbol or code                                |\n",
    "| OPEN              | Opening price of the stock                          |\n",
    "| HIGH              | Highest price reached during the interval           |\n",
    "| LOW               | Lowest price reached during the interval            |\n",
    "| PREV. CLOSE       | Previous day's closing price                        |\n",
    "| LTP               | Last traded price                                   |\n",
    "| CHNG              | Change in price (LTP - PREV. CLOSE)                 |\n",
    "| %CHNG             | Percentage change in price ((LTP - PREV. CLOSE) / PREV. CLOSE) * 100 |\n",
    "| VOLUME (shares)   | Total volume of shares traded                       |\n",
    "| VALUE             | Total value of shares traded                        |\n",
    "| 52W H             | 52-week high price                                  |\n",
    "| 52W L             | 52-week low price                                   |\n",
    "| 30 D %CHNG        | Percentage change in the last 30 days              |\n",
    "| 365 D % CHNG     | Percentage change in the last 365 days             |\n",
    "| 30-Sep-2022       | Date of the data                                   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Models\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\prashant\\Downloads\\MW-NIFTY-TOTAL-MARKET-30-Sep-2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL \\n</th>\n",
       "      <th>OPEN \\n</th>\n",
       "      <th>HIGH \\n</th>\n",
       "      <th>LOW \\n</th>\n",
       "      <th>PREV. CLOSE \\n</th>\n",
       "      <th>LTP \\n</th>\n",
       "      <th>CHNG \\n</th>\n",
       "      <th>%CHNG \\n</th>\n",
       "      <th>VOLUME \\n(shares)</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>52W H \\n</th>\n",
       "      <th>52W L \\n</th>\n",
       "      <th>30 D   %CHNG \\n</th>\n",
       "      <th>365 D % CHNG \\n 29-Sep-2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIFTY TOTAL MARKET</td>\n",
       "      <td>9,666.80</td>\n",
       "      <td>9,737.90</td>\n",
       "      <td>9,653.75</td>\n",
       "      <td>9,633.95</td>\n",
       "      <td>9,702.50</td>\n",
       "      <td>68.55</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2,64,96,91,885</td>\n",
       "      <td>6,23,10,52,42,041.43</td>\n",
       "      <td>9,961.40</td>\n",
       "      <td>7,145.35</td>\n",
       "      <td>1.93</td>\n",
       "      <td>19.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDELWEISS</td>\n",
       "      <td>54.5</td>\n",
       "      <td>62.55</td>\n",
       "      <td>54.25</td>\n",
       "      <td>54.1</td>\n",
       "      <td>61.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>13.86</td>\n",
       "      <td>4,55,07,201</td>\n",
       "      <td>2,68,17,39,354.93</td>\n",
       "      <td>77.4</td>\n",
       "      <td>35</td>\n",
       "      <td>9.77</td>\n",
       "      <td>4.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GMDCLTD</td>\n",
       "      <td>284.35</td>\n",
       "      <td>323.85</td>\n",
       "      <td>284</td>\n",
       "      <td>282.95</td>\n",
       "      <td>315.8</td>\n",
       "      <td>32.85</td>\n",
       "      <td>11.61</td>\n",
       "      <td>2,38,00,714</td>\n",
       "      <td>7,37,86,97,354.28</td>\n",
       "      <td>323.85</td>\n",
       "      <td>122.7</td>\n",
       "      <td>25.78</td>\n",
       "      <td>138.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLENMARK</td>\n",
       "      <td>783.75</td>\n",
       "      <td>861.7</td>\n",
       "      <td>782.1</td>\n",
       "      <td>776.95</td>\n",
       "      <td>854.8</td>\n",
       "      <td>77.85</td>\n",
       "      <td>10.02</td>\n",
       "      <td>94,06,251</td>\n",
       "      <td>7,90,77,41,153.19</td>\n",
       "      <td>880</td>\n",
       "      <td>368</td>\n",
       "      <td>13.26</td>\n",
       "      <td>121.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHOKA</td>\n",
       "      <td>112.8</td>\n",
       "      <td>123.3</td>\n",
       "      <td>111.8</td>\n",
       "      <td>112.15</td>\n",
       "      <td>123.1</td>\n",
       "      <td>10.95</td>\n",
       "      <td>9.76</td>\n",
       "      <td>1,77,16,622</td>\n",
       "      <td>2,11,23,52,841.06</td>\n",
       "      <td>123.3</td>\n",
       "      <td>70.15</td>\n",
       "      <td>20.96</td>\n",
       "      <td>55.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>TIINDIA</td>\n",
       "      <td>3,040.00</td>\n",
       "      <td>3,100.30</td>\n",
       "      <td>2,905.00</td>\n",
       "      <td>3,103.80</td>\n",
       "      <td>2,985.00</td>\n",
       "      <td>-118.8</td>\n",
       "      <td>-3.83</td>\n",
       "      <td>13,12,908</td>\n",
       "      <td>3,89,84,43,982.56</td>\n",
       "      <td>3,736.40</td>\n",
       "      <td>2,375.00</td>\n",
       "      <td>5.31</td>\n",
       "      <td>15.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>TATAINVEST</td>\n",
       "      <td>3,437.95</td>\n",
       "      <td>3,475.00</td>\n",
       "      <td>3,245.55</td>\n",
       "      <td>3,440.60</td>\n",
       "      <td>3,280.00</td>\n",
       "      <td>-160.6</td>\n",
       "      <td>-4.67</td>\n",
       "      <td>6,92,221</td>\n",
       "      <td>2,30,70,41,071.01</td>\n",
       "      <td>3,521.00</td>\n",
       "      <td>1,730.00</td>\n",
       "      <td>34.63</td>\n",
       "      <td>46.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>HNDFDS</td>\n",
       "      <td>573.85</td>\n",
       "      <td>574.05</td>\n",
       "      <td>531.55</td>\n",
       "      <td>568.4</td>\n",
       "      <td>537</td>\n",
       "      <td>-31.4</td>\n",
       "      <td>-5.52</td>\n",
       "      <td>4,57,467</td>\n",
       "      <td>24,87,70,554.60</td>\n",
       "      <td>749</td>\n",
       "      <td>405</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>18.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>FINCABLES</td>\n",
       "      <td>1,200.00</td>\n",
       "      <td>1,216.25</td>\n",
       "      <td>1,110.50</td>\n",
       "      <td>1,195.55</td>\n",
       "      <td>1,116.00</td>\n",
       "      <td>-79.55</td>\n",
       "      <td>-6.65</td>\n",
       "      <td>11,17,926</td>\n",
       "      <td>1,28,95,83,537.30</td>\n",
       "      <td>1,219.00</td>\n",
       "      <td>445.8</td>\n",
       "      <td>3.28</td>\n",
       "      <td>137.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>NAVINFLUOR</td>\n",
       "      <td>4,000.00</td>\n",
       "      <td>4,000.05</td>\n",
       "      <td>3,726.65</td>\n",
       "      <td>4,357.65</td>\n",
       "      <td>3,764.00</td>\n",
       "      <td>-593.65</td>\n",
       "      <td>-13.62</td>\n",
       "      <td>32,46,796</td>\n",
       "      <td>12,31,82,46,620.12</td>\n",
       "      <td>4,950.00</td>\n",
       "      <td>3,726.65</td>\n",
       "      <td>-18.59</td>\n",
       "      <td>-15.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              SYMBOL \\n   OPEN \\n   HIGH \\n    LOW \\n PREV. CLOSE \\n  \\\n",
       "0    NIFTY TOTAL MARKET  9,666.80  9,737.90  9,653.75       9,633.95   \n",
       "1             EDELWEISS      54.5     62.55     54.25           54.1   \n",
       "2               GMDCLTD    284.35    323.85       284         282.95   \n",
       "3              GLENMARK    783.75     861.7     782.1         776.95   \n",
       "4                ASHOKA     112.8     123.3     111.8         112.15   \n",
       "..                  ...       ...       ...       ...            ...   \n",
       "747             TIINDIA  3,040.00  3,100.30  2,905.00       3,103.80   \n",
       "748          TATAINVEST  3,437.95  3,475.00  3,245.55       3,440.60   \n",
       "749              HNDFDS    573.85    574.05    531.55          568.4   \n",
       "750           FINCABLES  1,200.00  1,216.25  1,110.50       1,195.55   \n",
       "751          NAVINFLUOR  4,000.00  4,000.05  3,726.65       4,357.65   \n",
       "\n",
       "       LTP \\n  CHNG \\n %CHNG \\n VOLUME \\n(shares)                VALUE   \\\n",
       "0    9,702.50    68.55     0.71    2,64,96,91,885  6,23,10,52,42,041.43   \n",
       "1        61.6      7.5    13.86       4,55,07,201     2,68,17,39,354.93   \n",
       "2       315.8    32.85    11.61       2,38,00,714     7,37,86,97,354.28   \n",
       "3       854.8    77.85    10.02         94,06,251     7,90,77,41,153.19   \n",
       "4       123.1    10.95     9.76       1,77,16,622     2,11,23,52,841.06   \n",
       "..        ...      ...      ...               ...                   ...   \n",
       "747  2,985.00   -118.8    -3.83         13,12,908     3,89,84,43,982.56   \n",
       "748  3,280.00   -160.6    -4.67          6,92,221     2,30,70,41,071.01   \n",
       "749       537    -31.4    -5.52          4,57,467       24,87,70,554.60   \n",
       "750  1,116.00   -79.55    -6.65         11,17,926     1,28,95,83,537.30   \n",
       "751  3,764.00  -593.65   -13.62         32,46,796    12,31,82,46,620.12   \n",
       "\n",
       "     52W H \\n  52W L \\n 30 D   %CHNG \\n 365 D % CHNG \\n 29-Sep-2022  \n",
       "0    9,961.40  7,145.35            1.93                       19.32  \n",
       "1        77.4        35            9.77                        4.08  \n",
       "2      323.85     122.7           25.78                       138.1  \n",
       "3         880       368           13.26                      121.06  \n",
       "4       123.3     70.15           20.96                       55.86  \n",
       "..        ...       ...             ...                         ...  \n",
       "747  3,736.40  2,375.00            5.31                       15.65  \n",
       "748  3,521.00  1,730.00           34.63                       46.23  \n",
       "749       749       405           -2.12                       18.09  \n",
       "750  1,219.00     445.8            3.28                      137.42  \n",
       "751  4,950.00  3,726.65          -18.59                      -15.61  \n",
       "\n",
       "[752 rows x 14 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SYMBOL \\n', 'OPEN \\n', 'HIGH \\n', 'LOW \\n', 'PREV. CLOSE \\n', 'LTP \\n',\n",
       "       'CHNG \\n', '%CHNG \\n', 'VOLUME \\n(shares)', 'VALUE ', '52W H \\n',\n",
       "       '52W L \\n', '30 D   %CHNG \\n', '365 D % CHNG \\n 29-Sep-2022'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>PREV. CLOSE</th>\n",
       "      <th>LTP</th>\n",
       "      <th>CHNG</th>\n",
       "      <th>%CHNG</th>\n",
       "      <th>VOLUME \\n(shares)</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>52W H</th>\n",
       "      <th>52W L</th>\n",
       "      <th>30 D   %CHNG</th>\n",
       "      <th>365 D % CHNG \\n 29-Sep-2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIFTY TOTAL MARKET</td>\n",
       "      <td>9,666.80</td>\n",
       "      <td>9,737.90</td>\n",
       "      <td>9,653.75</td>\n",
       "      <td>9,633.95</td>\n",
       "      <td>9,702.50</td>\n",
       "      <td>68.55</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2,64,96,91,885</td>\n",
       "      <td>6,23,10,52,42,041.43</td>\n",
       "      <td>9,961.40</td>\n",
       "      <td>7,145.35</td>\n",
       "      <td>1.93</td>\n",
       "      <td>19.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDELWEISS</td>\n",
       "      <td>54.5</td>\n",
       "      <td>62.55</td>\n",
       "      <td>54.25</td>\n",
       "      <td>54.1</td>\n",
       "      <td>61.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>13.86</td>\n",
       "      <td>4,55,07,201</td>\n",
       "      <td>2,68,17,39,354.93</td>\n",
       "      <td>77.4</td>\n",
       "      <td>35</td>\n",
       "      <td>9.77</td>\n",
       "      <td>4.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GMDCLTD</td>\n",
       "      <td>284.35</td>\n",
       "      <td>323.85</td>\n",
       "      <td>284</td>\n",
       "      <td>282.95</td>\n",
       "      <td>315.8</td>\n",
       "      <td>32.85</td>\n",
       "      <td>11.61</td>\n",
       "      <td>2,38,00,714</td>\n",
       "      <td>7,37,86,97,354.28</td>\n",
       "      <td>323.85</td>\n",
       "      <td>122.7</td>\n",
       "      <td>25.78</td>\n",
       "      <td>138.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLENMARK</td>\n",
       "      <td>783.75</td>\n",
       "      <td>861.7</td>\n",
       "      <td>782.1</td>\n",
       "      <td>776.95</td>\n",
       "      <td>854.8</td>\n",
       "      <td>77.85</td>\n",
       "      <td>10.02</td>\n",
       "      <td>94,06,251</td>\n",
       "      <td>7,90,77,41,153.19</td>\n",
       "      <td>880</td>\n",
       "      <td>368</td>\n",
       "      <td>13.26</td>\n",
       "      <td>121.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHOKA</td>\n",
       "      <td>112.8</td>\n",
       "      <td>123.3</td>\n",
       "      <td>111.8</td>\n",
       "      <td>112.15</td>\n",
       "      <td>123.1</td>\n",
       "      <td>10.95</td>\n",
       "      <td>9.76</td>\n",
       "      <td>1,77,16,622</td>\n",
       "      <td>2,11,23,52,841.06</td>\n",
       "      <td>123.3</td>\n",
       "      <td>70.15</td>\n",
       "      <td>20.96</td>\n",
       "      <td>55.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>TIINDIA</td>\n",
       "      <td>3,040.00</td>\n",
       "      <td>3,100.30</td>\n",
       "      <td>2,905.00</td>\n",
       "      <td>3,103.80</td>\n",
       "      <td>2,985.00</td>\n",
       "      <td>-118.8</td>\n",
       "      <td>-3.83</td>\n",
       "      <td>13,12,908</td>\n",
       "      <td>3,89,84,43,982.56</td>\n",
       "      <td>3,736.40</td>\n",
       "      <td>2,375.00</td>\n",
       "      <td>5.31</td>\n",
       "      <td>15.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>TATAINVEST</td>\n",
       "      <td>3,437.95</td>\n",
       "      <td>3,475.00</td>\n",
       "      <td>3,245.55</td>\n",
       "      <td>3,440.60</td>\n",
       "      <td>3,280.00</td>\n",
       "      <td>-160.6</td>\n",
       "      <td>-4.67</td>\n",
       "      <td>6,92,221</td>\n",
       "      <td>2,30,70,41,071.01</td>\n",
       "      <td>3,521.00</td>\n",
       "      <td>1,730.00</td>\n",
       "      <td>34.63</td>\n",
       "      <td>46.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>HNDFDS</td>\n",
       "      <td>573.85</td>\n",
       "      <td>574.05</td>\n",
       "      <td>531.55</td>\n",
       "      <td>568.4</td>\n",
       "      <td>537</td>\n",
       "      <td>-31.4</td>\n",
       "      <td>-5.52</td>\n",
       "      <td>4,57,467</td>\n",
       "      <td>24,87,70,554.60</td>\n",
       "      <td>749</td>\n",
       "      <td>405</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>18.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>FINCABLES</td>\n",
       "      <td>1,200.00</td>\n",
       "      <td>1,216.25</td>\n",
       "      <td>1,110.50</td>\n",
       "      <td>1,195.55</td>\n",
       "      <td>1,116.00</td>\n",
       "      <td>-79.55</td>\n",
       "      <td>-6.65</td>\n",
       "      <td>11,17,926</td>\n",
       "      <td>1,28,95,83,537.30</td>\n",
       "      <td>1,219.00</td>\n",
       "      <td>445.8</td>\n",
       "      <td>3.28</td>\n",
       "      <td>137.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>NAVINFLUOR</td>\n",
       "      <td>4,000.00</td>\n",
       "      <td>4,000.05</td>\n",
       "      <td>3,726.65</td>\n",
       "      <td>4,357.65</td>\n",
       "      <td>3,764.00</td>\n",
       "      <td>-593.65</td>\n",
       "      <td>-13.62</td>\n",
       "      <td>32,46,796</td>\n",
       "      <td>12,31,82,46,620.12</td>\n",
       "      <td>4,950.00</td>\n",
       "      <td>3,726.65</td>\n",
       "      <td>-18.59</td>\n",
       "      <td>-15.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SYMBOL      OPEN      HIGH       LOW PREV. CLOSE       LTP  \\\n",
       "0    NIFTY TOTAL MARKET  9,666.80  9,737.90  9,653.75    9,633.95  9,702.50   \n",
       "1             EDELWEISS      54.5     62.55     54.25        54.1      61.6   \n",
       "2               GMDCLTD    284.35    323.85       284      282.95     315.8   \n",
       "3              GLENMARK    783.75     861.7     782.1      776.95     854.8   \n",
       "4                ASHOKA     112.8     123.3     111.8      112.15     123.1   \n",
       "..                  ...       ...       ...       ...         ...       ...   \n",
       "747             TIINDIA  3,040.00  3,100.30  2,905.00    3,103.80  2,985.00   \n",
       "748          TATAINVEST  3,437.95  3,475.00  3,245.55    3,440.60  3,280.00   \n",
       "749              HNDFDS    573.85    574.05    531.55       568.4       537   \n",
       "750           FINCABLES  1,200.00  1,216.25  1,110.50    1,195.55  1,116.00   \n",
       "751          NAVINFLUOR  4,000.00  4,000.05  3,726.65    4,357.65  3,764.00   \n",
       "\n",
       "        CHNG   %CHNG VOLUME \\n(shares)                 VALUE     52W H  \\\n",
       "0      68.55    0.71    2,64,96,91,885  6,23,10,52,42,041.43  9,961.40   \n",
       "1        7.5   13.86       4,55,07,201     2,68,17,39,354.93      77.4   \n",
       "2      32.85   11.61       2,38,00,714     7,37,86,97,354.28    323.85   \n",
       "3      77.85   10.02         94,06,251     7,90,77,41,153.19       880   \n",
       "4      10.95    9.76       1,77,16,622     2,11,23,52,841.06     123.3   \n",
       "..       ...     ...               ...                   ...       ...   \n",
       "747   -118.8   -3.83         13,12,908     3,89,84,43,982.56  3,736.40   \n",
       "748   -160.6   -4.67          6,92,221     2,30,70,41,071.01  3,521.00   \n",
       "749    -31.4   -5.52          4,57,467       24,87,70,554.60       749   \n",
       "750   -79.55   -6.65         11,17,926     1,28,95,83,537.30  1,219.00   \n",
       "751  -593.65  -13.62         32,46,796    12,31,82,46,620.12  4,950.00   \n",
       "\n",
       "        52W L 30 D   %CHNG 365 D % CHNG \\n 29-Sep-2022  \n",
       "0    7,145.35         1.93                       19.32  \n",
       "1          35         9.77                        4.08  \n",
       "2       122.7        25.78                       138.1  \n",
       "3         368        13.26                      121.06  \n",
       "4       70.15        20.96                       55.86  \n",
       "..        ...          ...                         ...  \n",
       "747  2,375.00         5.31                       15.65  \n",
       "748  1,730.00        34.63                       46.23  \n",
       "749       405        -2.12                       18.09  \n",
       "750     445.8         3.28                      137.42  \n",
       "751  3,726.65       -18.59                      -15.61  \n",
       "\n",
       "[752 rows x 14 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_mapping = {col: col.strip() for col in df.columns}\n",
    "\n",
    "# Rename columns\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 752 entries, 0 to 751\n",
      "Data columns (total 14 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   SYMBOL                      752 non-null    object\n",
      " 1   OPEN                        752 non-null    object\n",
      " 2   HIGH                        752 non-null    object\n",
      " 3   LOW                         752 non-null    object\n",
      " 4   PREV. CLOSE                 752 non-null    object\n",
      " 5   LTP                         752 non-null    object\n",
      " 6   CHNG                        752 non-null    object\n",
      " 7   %CHNG                       752 non-null    object\n",
      " 8   VOLUME \n",
      "(shares)            752 non-null    object\n",
      " 9   VALUE                       752 non-null    object\n",
      " 10  52W H                       752 non-null    object\n",
      " 11  52W L                       752 non-null    object\n",
      " 12  30 D   %CHNG                752 non-null    object\n",
      " 13  365 D % CHNG \n",
      " 29-Sep-2022  752 non-null    object\n",
      "dtypes: object(14)\n",
      "memory usage: 82.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SYMBOL', 'OPEN', 'HIGH', 'LOW', 'PREV. CLOSE', 'LTP', 'CHNG', '%CHNG',\n",
       "       'VOLUME \\n(shares)', 'VALUE', '52W H', '52W L', '30 D   %CHNG',\n",
       "       '365 D % CHNG \\n 29-Sep-2022'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 SYMBOL     OPEN     HIGH      LOW  PREV. CLOSE     LTP  \\\n",
      "0    NIFTY TOTAL MARKET  9666.80  9737.90  9653.75      9633.95  9702.5   \n",
      "1             EDELWEISS    54.50    62.55    54.25        54.10    61.6   \n",
      "2               GMDCLTD   284.35   323.85   284.00       282.95   315.8   \n",
      "3              GLENMARK   783.75   861.70   782.10       776.95   854.8   \n",
      "4                ASHOKA   112.80   123.30   111.80       112.15   123.1   \n",
      "..                  ...      ...      ...      ...          ...     ...   \n",
      "747             TIINDIA  3040.00  3100.30  2905.00      3103.80  2985.0   \n",
      "748          TATAINVEST  3437.95  3475.00  3245.55      3440.60  3280.0   \n",
      "749              HNDFDS   573.85   574.05   531.55       568.40   537.0   \n",
      "750           FINCABLES  1200.00  1216.25  1110.50      1195.55  1116.0   \n",
      "751          NAVINFLUOR  4000.00  4000.05  3726.65      4357.65  3764.0   \n",
      "\n",
      "       CHNG  %CHNG  VOLUME \\n(shares)         VALUE    52W H    52W L  \\\n",
      "0     68.55   0.71         2649691885  6.231052e+11  9961.40  7145.35   \n",
      "1      7.50  13.86           45507201  2.681739e+09    77.40    35.00   \n",
      "2     32.85  11.61           23800714  7.378697e+09   323.85   122.70   \n",
      "3     77.85  10.02            9406251  7.907741e+09   880.00   368.00   \n",
      "4     10.95   9.76           17716622  2.112353e+09   123.30    70.15   \n",
      "..      ...    ...                ...           ...      ...      ...   \n",
      "747 -118.80  -3.83            1312908  3.898444e+09  3736.40  2375.00   \n",
      "748 -160.60  -4.67             692221  2.307041e+09  3521.00  1730.00   \n",
      "749  -31.40  -5.52             457467  2.487706e+08   749.00   405.00   \n",
      "750  -79.55  -6.65            1117926  1.289584e+09  1219.00   445.80   \n",
      "751 -593.65 -13.62            3246796  1.231825e+10  4950.00  3726.65   \n",
      "\n",
      "     30 D   %CHNG  365 D % CHNG \\n 29-Sep-2022  \n",
      "0            1.93                        19.32  \n",
      "1            9.77                         4.08  \n",
      "2           25.78                       138.10  \n",
      "3           13.26                       121.06  \n",
      "4           20.96                        55.86  \n",
      "..            ...                          ...  \n",
      "747          5.31                        15.65  \n",
      "748         34.63                        46.23  \n",
      "749         -2.12                        18.09  \n",
      "750          3.28                       137.42  \n",
      "751        -18.59                       -15.61  \n",
      "\n",
      "[752 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a function to remove special characters and convert to numeric\n",
    "def clean_and_convert(column):\n",
    "    cleaned = column.str.replace(',', '', regex=True).str.replace('%', '', regex=True)\n",
    "    return pd.to_numeric(cleaned, errors='coerce')\n",
    "\n",
    "# List of columns to convert to numeric\n",
    "columns_to_convert = ['OPEN', 'HIGH', 'LOW', 'PREV. CLOSE', 'LTP', 'CHNG', '%CHNG',\n",
    "       'VOLUME \\n(shares)', 'VALUE', '52W H', '52W L', '30 D   %CHNG',\n",
    "       '365 D % CHNG \\n 29-Sep-2022']\n",
    "\n",
    "# Convert and clean selected columns\n",
    "for col in columns_to_convert:\n",
    "    df[col] = clean_and_convert(df[col])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>PREV. CLOSE</th>\n",
       "      <th>LTP</th>\n",
       "      <th>CHNG</th>\n",
       "      <th>%CHNG</th>\n",
       "      <th>VOLUME \\n(shares)</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>52W H</th>\n",
       "      <th>52W L</th>\n",
       "      <th>30 D   %CHNG</th>\n",
       "      <th>365 D % CHNG \\n 29-Sep-2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIFTY TOTAL MARKET</td>\n",
       "      <td>9666.80</td>\n",
       "      <td>9737.90</td>\n",
       "      <td>9653.75</td>\n",
       "      <td>9633.95</td>\n",
       "      <td>9702.5</td>\n",
       "      <td>68.55</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2649691885</td>\n",
       "      <td>6.231052e+11</td>\n",
       "      <td>9961.40</td>\n",
       "      <td>7145.35</td>\n",
       "      <td>1.93</td>\n",
       "      <td>19.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDELWEISS</td>\n",
       "      <td>54.50</td>\n",
       "      <td>62.55</td>\n",
       "      <td>54.25</td>\n",
       "      <td>54.10</td>\n",
       "      <td>61.6</td>\n",
       "      <td>7.50</td>\n",
       "      <td>13.86</td>\n",
       "      <td>45507201</td>\n",
       "      <td>2.681739e+09</td>\n",
       "      <td>77.40</td>\n",
       "      <td>35.00</td>\n",
       "      <td>9.77</td>\n",
       "      <td>4.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GMDCLTD</td>\n",
       "      <td>284.35</td>\n",
       "      <td>323.85</td>\n",
       "      <td>284.00</td>\n",
       "      <td>282.95</td>\n",
       "      <td>315.8</td>\n",
       "      <td>32.85</td>\n",
       "      <td>11.61</td>\n",
       "      <td>23800714</td>\n",
       "      <td>7.378697e+09</td>\n",
       "      <td>323.85</td>\n",
       "      <td>122.70</td>\n",
       "      <td>25.78</td>\n",
       "      <td>138.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLENMARK</td>\n",
       "      <td>783.75</td>\n",
       "      <td>861.70</td>\n",
       "      <td>782.10</td>\n",
       "      <td>776.95</td>\n",
       "      <td>854.8</td>\n",
       "      <td>77.85</td>\n",
       "      <td>10.02</td>\n",
       "      <td>9406251</td>\n",
       "      <td>7.907741e+09</td>\n",
       "      <td>880.00</td>\n",
       "      <td>368.00</td>\n",
       "      <td>13.26</td>\n",
       "      <td>121.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHOKA</td>\n",
       "      <td>112.80</td>\n",
       "      <td>123.30</td>\n",
       "      <td>111.80</td>\n",
       "      <td>112.15</td>\n",
       "      <td>123.1</td>\n",
       "      <td>10.95</td>\n",
       "      <td>9.76</td>\n",
       "      <td>17716622</td>\n",
       "      <td>2.112353e+09</td>\n",
       "      <td>123.30</td>\n",
       "      <td>70.15</td>\n",
       "      <td>20.96</td>\n",
       "      <td>55.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>TIINDIA</td>\n",
       "      <td>3040.00</td>\n",
       "      <td>3100.30</td>\n",
       "      <td>2905.00</td>\n",
       "      <td>3103.80</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>-118.80</td>\n",
       "      <td>-3.83</td>\n",
       "      <td>1312908</td>\n",
       "      <td>3.898444e+09</td>\n",
       "      <td>3736.40</td>\n",
       "      <td>2375.00</td>\n",
       "      <td>5.31</td>\n",
       "      <td>15.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>TATAINVEST</td>\n",
       "      <td>3437.95</td>\n",
       "      <td>3475.00</td>\n",
       "      <td>3245.55</td>\n",
       "      <td>3440.60</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>-160.60</td>\n",
       "      <td>-4.67</td>\n",
       "      <td>692221</td>\n",
       "      <td>2.307041e+09</td>\n",
       "      <td>3521.00</td>\n",
       "      <td>1730.00</td>\n",
       "      <td>34.63</td>\n",
       "      <td>46.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>HNDFDS</td>\n",
       "      <td>573.85</td>\n",
       "      <td>574.05</td>\n",
       "      <td>531.55</td>\n",
       "      <td>568.40</td>\n",
       "      <td>537.0</td>\n",
       "      <td>-31.40</td>\n",
       "      <td>-5.52</td>\n",
       "      <td>457467</td>\n",
       "      <td>2.487706e+08</td>\n",
       "      <td>749.00</td>\n",
       "      <td>405.00</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>18.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>FINCABLES</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>1216.25</td>\n",
       "      <td>1110.50</td>\n",
       "      <td>1195.55</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>-79.55</td>\n",
       "      <td>-6.65</td>\n",
       "      <td>1117926</td>\n",
       "      <td>1.289584e+09</td>\n",
       "      <td>1219.00</td>\n",
       "      <td>445.80</td>\n",
       "      <td>3.28</td>\n",
       "      <td>137.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>NAVINFLUOR</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>4000.05</td>\n",
       "      <td>3726.65</td>\n",
       "      <td>4357.65</td>\n",
       "      <td>3764.0</td>\n",
       "      <td>-593.65</td>\n",
       "      <td>-13.62</td>\n",
       "      <td>3246796</td>\n",
       "      <td>1.231825e+10</td>\n",
       "      <td>4950.00</td>\n",
       "      <td>3726.65</td>\n",
       "      <td>-18.59</td>\n",
       "      <td>-15.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SYMBOL     OPEN     HIGH      LOW  PREV. CLOSE     LTP  \\\n",
       "0    NIFTY TOTAL MARKET  9666.80  9737.90  9653.75      9633.95  9702.5   \n",
       "1             EDELWEISS    54.50    62.55    54.25        54.10    61.6   \n",
       "2               GMDCLTD   284.35   323.85   284.00       282.95   315.8   \n",
       "3              GLENMARK   783.75   861.70   782.10       776.95   854.8   \n",
       "4                ASHOKA   112.80   123.30   111.80       112.15   123.1   \n",
       "..                  ...      ...      ...      ...          ...     ...   \n",
       "747             TIINDIA  3040.00  3100.30  2905.00      3103.80  2985.0   \n",
       "748          TATAINVEST  3437.95  3475.00  3245.55      3440.60  3280.0   \n",
       "749              HNDFDS   573.85   574.05   531.55       568.40   537.0   \n",
       "750           FINCABLES  1200.00  1216.25  1110.50      1195.55  1116.0   \n",
       "751          NAVINFLUOR  4000.00  4000.05  3726.65      4357.65  3764.0   \n",
       "\n",
       "       CHNG  %CHNG  VOLUME \\n(shares)         VALUE    52W H    52W L  \\\n",
       "0     68.55   0.71         2649691885  6.231052e+11  9961.40  7145.35   \n",
       "1      7.50  13.86           45507201  2.681739e+09    77.40    35.00   \n",
       "2     32.85  11.61           23800714  7.378697e+09   323.85   122.70   \n",
       "3     77.85  10.02            9406251  7.907741e+09   880.00   368.00   \n",
       "4     10.95   9.76           17716622  2.112353e+09   123.30    70.15   \n",
       "..      ...    ...                ...           ...      ...      ...   \n",
       "747 -118.80  -3.83            1312908  3.898444e+09  3736.40  2375.00   \n",
       "748 -160.60  -4.67             692221  2.307041e+09  3521.00  1730.00   \n",
       "749  -31.40  -5.52             457467  2.487706e+08   749.00   405.00   \n",
       "750  -79.55  -6.65            1117926  1.289584e+09  1219.00   445.80   \n",
       "751 -593.65 -13.62            3246796  1.231825e+10  4950.00  3726.65   \n",
       "\n",
       "     30 D   %CHNG  365 D % CHNG \\n 29-Sep-2022  \n",
       "0            1.93                        19.32  \n",
       "1            9.77                         4.08  \n",
       "2           25.78                       138.10  \n",
       "3           13.26                       121.06  \n",
       "4           20.96                        55.86  \n",
       "..            ...                          ...  \n",
       "747          5.31                        15.65  \n",
       "748         34.63                        46.23  \n",
       "749         -2.12                        18.09  \n",
       "750          3.28                       137.42  \n",
       "751        -18.59                       -15.61  \n",
       "\n",
       "[752 rows x 14 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 752 entries, 0 to 751\n",
      "Data columns (total 14 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   SYMBOL                      752 non-null    object \n",
      " 1   OPEN                        752 non-null    float64\n",
      " 2   HIGH                        752 non-null    float64\n",
      " 3   LOW                         752 non-null    float64\n",
      " 4   PREV. CLOSE                 752 non-null    float64\n",
      " 5   LTP                         752 non-null    float64\n",
      " 6   CHNG                        747 non-null    float64\n",
      " 7   %CHNG                       747 non-null    float64\n",
      " 8   VOLUME \n",
      "(shares)            752 non-null    int64  \n",
      " 9   VALUE                       752 non-null    float64\n",
      " 10  52W H                       752 non-null    float64\n",
      " 11  52W L                       752 non-null    float64\n",
      " 12  30 D   %CHNG                747 non-null    float64\n",
      " 13  365 D % CHNG \n",
      " 29-Sep-2022  707 non-null    float64\n",
      "dtypes: float64(12), int64(1), object(1)\n",
      "memory usage: 82.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SYMBOL                          0\n",
       "OPEN                            0\n",
       "HIGH                            0\n",
       "LOW                             0\n",
       "PREV. CLOSE                     0\n",
       "LTP                             0\n",
       "CHNG                            5\n",
       "%CHNG                           5\n",
       "VOLUME \\n(shares)               0\n",
       "VALUE                           0\n",
       "52W H                           0\n",
       "52W L                           0\n",
       "30 D   %CHNG                    5\n",
       "365 D % CHNG \\n 29-Sep-2022    45\n",
       "dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SYMBOL                         0\n",
       "OPEN                           0\n",
       "HIGH                           0\n",
       "LOW                            0\n",
       "PREV. CLOSE                    0\n",
       "LTP                            0\n",
       "CHNG                           0\n",
       "%CHNG                          0\n",
       "VOLUME \\n(shares)              0\n",
       "VALUE                          0\n",
       "52W H                          0\n",
       "52W L                          0\n",
       "30 D   %CHNG                   0\n",
       "365 D % CHNG \\n 29-Sep-2022    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>PREV. CLOSE</th>\n",
       "      <th>LTP</th>\n",
       "      <th>CHNG</th>\n",
       "      <th>%CHNG</th>\n",
       "      <th>VOLUME \\n(shares)</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>52W H</th>\n",
       "      <th>52W L</th>\n",
       "      <th>30 D   %CHNG</th>\n",
       "      <th>365 D % CHNG \\n 29-Sep-2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIFTY TOTAL MARKET</td>\n",
       "      <td>9666.80</td>\n",
       "      <td>9737.90</td>\n",
       "      <td>9653.75</td>\n",
       "      <td>9633.95</td>\n",
       "      <td>9702.5</td>\n",
       "      <td>68.55</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2649691885</td>\n",
       "      <td>6.231052e+11</td>\n",
       "      <td>9961.40</td>\n",
       "      <td>7145.35</td>\n",
       "      <td>1.93</td>\n",
       "      <td>19.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDELWEISS</td>\n",
       "      <td>54.50</td>\n",
       "      <td>62.55</td>\n",
       "      <td>54.25</td>\n",
       "      <td>54.10</td>\n",
       "      <td>61.6</td>\n",
       "      <td>7.50</td>\n",
       "      <td>13.86</td>\n",
       "      <td>45507201</td>\n",
       "      <td>2.681739e+09</td>\n",
       "      <td>77.40</td>\n",
       "      <td>35.00</td>\n",
       "      <td>9.77</td>\n",
       "      <td>4.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GMDCLTD</td>\n",
       "      <td>284.35</td>\n",
       "      <td>323.85</td>\n",
       "      <td>284.00</td>\n",
       "      <td>282.95</td>\n",
       "      <td>315.8</td>\n",
       "      <td>32.85</td>\n",
       "      <td>11.61</td>\n",
       "      <td>23800714</td>\n",
       "      <td>7.378697e+09</td>\n",
       "      <td>323.85</td>\n",
       "      <td>122.70</td>\n",
       "      <td>25.78</td>\n",
       "      <td>138.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLENMARK</td>\n",
       "      <td>783.75</td>\n",
       "      <td>861.70</td>\n",
       "      <td>782.10</td>\n",
       "      <td>776.95</td>\n",
       "      <td>854.8</td>\n",
       "      <td>77.85</td>\n",
       "      <td>10.02</td>\n",
       "      <td>9406251</td>\n",
       "      <td>7.907741e+09</td>\n",
       "      <td>880.00</td>\n",
       "      <td>368.00</td>\n",
       "      <td>13.26</td>\n",
       "      <td>121.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHOKA</td>\n",
       "      <td>112.80</td>\n",
       "      <td>123.30</td>\n",
       "      <td>111.80</td>\n",
       "      <td>112.15</td>\n",
       "      <td>123.1</td>\n",
       "      <td>10.95</td>\n",
       "      <td>9.76</td>\n",
       "      <td>17716622</td>\n",
       "      <td>2.112353e+09</td>\n",
       "      <td>123.30</td>\n",
       "      <td>70.15</td>\n",
       "      <td>20.96</td>\n",
       "      <td>55.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SYMBOL     OPEN     HIGH      LOW  PREV. CLOSE     LTP   CHNG  \\\n",
       "0  NIFTY TOTAL MARKET  9666.80  9737.90  9653.75      9633.95  9702.5  68.55   \n",
       "1           EDELWEISS    54.50    62.55    54.25        54.10    61.6   7.50   \n",
       "2             GMDCLTD   284.35   323.85   284.00       282.95   315.8  32.85   \n",
       "3            GLENMARK   783.75   861.70   782.10       776.95   854.8  77.85   \n",
       "4              ASHOKA   112.80   123.30   111.80       112.15   123.1  10.95   \n",
       "\n",
       "   %CHNG  VOLUME \\n(shares)         VALUE    52W H    52W L  30 D   %CHNG  \\\n",
       "0   0.71         2649691885  6.231052e+11  9961.40  7145.35          1.93   \n",
       "1  13.86           45507201  2.681739e+09    77.40    35.00          9.77   \n",
       "2  11.61           23800714  7.378697e+09   323.85   122.70         25.78   \n",
       "3  10.02            9406251  7.907741e+09   880.00   368.00         13.26   \n",
       "4   9.76           17716622  2.112353e+09   123.30    70.15         20.96   \n",
       "\n",
       "   365 D % CHNG \\n 29-Sep-2022  \n",
       "0                        19.32  \n",
       "1                         4.08  \n",
       "2                       138.10  \n",
       "3                       121.06  \n",
       "4                        55.86  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Daily Return'] = (df['LTP'] - df['PREV. CLOSE']) / df['PREV. CLOSE']\n",
    "\n",
    "# Calculate volatility (assuming a 30-day period)\n",
    "window = 30  # You can change this window size as needed\n",
    "df['Volatility'] = df['Daily Return'].rolling(window=window).std() * (365 ** 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>PREV. CLOSE</th>\n",
       "      <th>LTP</th>\n",
       "      <th>CHNG</th>\n",
       "      <th>%CHNG</th>\n",
       "      <th>VOLUME \\n(shares)</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>52W H</th>\n",
       "      <th>52W L</th>\n",
       "      <th>30 D   %CHNG</th>\n",
       "      <th>365 D % CHNG \\n 29-Sep-2022</th>\n",
       "      <th>Daily Return</th>\n",
       "      <th>Volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIFTY TOTAL MARKET</td>\n",
       "      <td>9666.80</td>\n",
       "      <td>9737.90</td>\n",
       "      <td>9653.75</td>\n",
       "      <td>9633.95</td>\n",
       "      <td>9702.5</td>\n",
       "      <td>68.55</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2649691885</td>\n",
       "      <td>6.231052e+11</td>\n",
       "      <td>9961.40</td>\n",
       "      <td>7145.35</td>\n",
       "      <td>1.93</td>\n",
       "      <td>19.32</td>\n",
       "      <td>0.007115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDELWEISS</td>\n",
       "      <td>54.50</td>\n",
       "      <td>62.55</td>\n",
       "      <td>54.25</td>\n",
       "      <td>54.10</td>\n",
       "      <td>61.6</td>\n",
       "      <td>7.50</td>\n",
       "      <td>13.86</td>\n",
       "      <td>45507201</td>\n",
       "      <td>2.681739e+09</td>\n",
       "      <td>77.40</td>\n",
       "      <td>35.00</td>\n",
       "      <td>9.77</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.138632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GMDCLTD</td>\n",
       "      <td>284.35</td>\n",
       "      <td>323.85</td>\n",
       "      <td>284.00</td>\n",
       "      <td>282.95</td>\n",
       "      <td>315.8</td>\n",
       "      <td>32.85</td>\n",
       "      <td>11.61</td>\n",
       "      <td>23800714</td>\n",
       "      <td>7.378697e+09</td>\n",
       "      <td>323.85</td>\n",
       "      <td>122.70</td>\n",
       "      <td>25.78</td>\n",
       "      <td>138.10</td>\n",
       "      <td>0.116098</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLENMARK</td>\n",
       "      <td>783.75</td>\n",
       "      <td>861.70</td>\n",
       "      <td>782.10</td>\n",
       "      <td>776.95</td>\n",
       "      <td>854.8</td>\n",
       "      <td>77.85</td>\n",
       "      <td>10.02</td>\n",
       "      <td>9406251</td>\n",
       "      <td>7.907741e+09</td>\n",
       "      <td>880.00</td>\n",
       "      <td>368.00</td>\n",
       "      <td>13.26</td>\n",
       "      <td>121.06</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHOKA</td>\n",
       "      <td>112.80</td>\n",
       "      <td>123.30</td>\n",
       "      <td>111.80</td>\n",
       "      <td>112.15</td>\n",
       "      <td>123.1</td>\n",
       "      <td>10.95</td>\n",
       "      <td>9.76</td>\n",
       "      <td>17716622</td>\n",
       "      <td>2.112353e+09</td>\n",
       "      <td>123.30</td>\n",
       "      <td>70.15</td>\n",
       "      <td>20.96</td>\n",
       "      <td>55.86</td>\n",
       "      <td>0.097637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SYMBOL     OPEN     HIGH      LOW  PREV. CLOSE     LTP   CHNG  \\\n",
       "0  NIFTY TOTAL MARKET  9666.80  9737.90  9653.75      9633.95  9702.5  68.55   \n",
       "1           EDELWEISS    54.50    62.55    54.25        54.10    61.6   7.50   \n",
       "2             GMDCLTD   284.35   323.85   284.00       282.95   315.8  32.85   \n",
       "3            GLENMARK   783.75   861.70   782.10       776.95   854.8  77.85   \n",
       "4              ASHOKA   112.80   123.30   111.80       112.15   123.1  10.95   \n",
       "\n",
       "   %CHNG  VOLUME \\n(shares)         VALUE    52W H    52W L  30 D   %CHNG  \\\n",
       "0   0.71         2649691885  6.231052e+11  9961.40  7145.35          1.93   \n",
       "1  13.86           45507201  2.681739e+09    77.40    35.00          9.77   \n",
       "2  11.61           23800714  7.378697e+09   323.85   122.70         25.78   \n",
       "3  10.02            9406251  7.907741e+09   880.00   368.00         13.26   \n",
       "4   9.76           17716622  2.112353e+09   123.30    70.15         20.96   \n",
       "\n",
       "   365 D % CHNG \\n 29-Sep-2022  Daily Return  Volatility  \n",
       "0                        19.32      0.007115         NaN  \n",
       "1                         4.08      0.138632         NaN  \n",
       "2                       138.10      0.116098         NaN  \n",
       "3                       121.06      0.100199         NaN  \n",
       "4                        55.86      0.097637         NaN  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SYMBOL                          0\n",
       "OPEN                            0\n",
       "HIGH                            0\n",
       "LOW                             0\n",
       "PREV. CLOSE                     0\n",
       "LTP                             0\n",
       "CHNG                            0\n",
       "%CHNG                           0\n",
       "VOLUME \\n(shares)               0\n",
       "VALUE                           0\n",
       "52W H                           0\n",
       "52W L                           0\n",
       "30 D   %CHNG                    0\n",
       "365 D % CHNG \\n 29-Sep-2022     0\n",
       "Daily Return                    0\n",
       "Volatility                     29\n",
       "dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>PREV. CLOSE</th>\n",
       "      <th>LTP</th>\n",
       "      <th>CHNG</th>\n",
       "      <th>%CHNG</th>\n",
       "      <th>VOLUME \\n(shares)</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>52W H</th>\n",
       "      <th>52W L</th>\n",
       "      <th>30 D   %CHNG</th>\n",
       "      <th>365 D % CHNG \\n 29-Sep-2022</th>\n",
       "      <th>Daily Return</th>\n",
       "      <th>Volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIFTY TOTAL MARKET</td>\n",
       "      <td>9666.80</td>\n",
       "      <td>9737.90</td>\n",
       "      <td>9653.75</td>\n",
       "      <td>9633.95</td>\n",
       "      <td>9702.5</td>\n",
       "      <td>68.55</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2649691885</td>\n",
       "      <td>6.231052e+11</td>\n",
       "      <td>9961.40</td>\n",
       "      <td>7145.35</td>\n",
       "      <td>1.93</td>\n",
       "      <td>19.32</td>\n",
       "      <td>0.007115</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDELWEISS</td>\n",
       "      <td>54.50</td>\n",
       "      <td>62.55</td>\n",
       "      <td>54.25</td>\n",
       "      <td>54.10</td>\n",
       "      <td>61.6</td>\n",
       "      <td>7.50</td>\n",
       "      <td>13.86</td>\n",
       "      <td>45507201</td>\n",
       "      <td>2.681739e+09</td>\n",
       "      <td>77.40</td>\n",
       "      <td>35.00</td>\n",
       "      <td>9.77</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.138632</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GMDCLTD</td>\n",
       "      <td>284.35</td>\n",
       "      <td>323.85</td>\n",
       "      <td>284.00</td>\n",
       "      <td>282.95</td>\n",
       "      <td>315.8</td>\n",
       "      <td>32.85</td>\n",
       "      <td>11.61</td>\n",
       "      <td>23800714</td>\n",
       "      <td>7.378697e+09</td>\n",
       "      <td>323.85</td>\n",
       "      <td>122.70</td>\n",
       "      <td>25.78</td>\n",
       "      <td>138.10</td>\n",
       "      <td>0.116098</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLENMARK</td>\n",
       "      <td>783.75</td>\n",
       "      <td>861.70</td>\n",
       "      <td>782.10</td>\n",
       "      <td>776.95</td>\n",
       "      <td>854.8</td>\n",
       "      <td>77.85</td>\n",
       "      <td>10.02</td>\n",
       "      <td>9406251</td>\n",
       "      <td>7.907741e+09</td>\n",
       "      <td>880.00</td>\n",
       "      <td>368.00</td>\n",
       "      <td>13.26</td>\n",
       "      <td>121.06</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHOKA</td>\n",
       "      <td>112.80</td>\n",
       "      <td>123.30</td>\n",
       "      <td>111.80</td>\n",
       "      <td>112.15</td>\n",
       "      <td>123.1</td>\n",
       "      <td>10.95</td>\n",
       "      <td>9.76</td>\n",
       "      <td>17716622</td>\n",
       "      <td>2.112353e+09</td>\n",
       "      <td>123.30</td>\n",
       "      <td>70.15</td>\n",
       "      <td>20.96</td>\n",
       "      <td>55.86</td>\n",
       "      <td>0.097637</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>TIINDIA</td>\n",
       "      <td>3040.00</td>\n",
       "      <td>3100.30</td>\n",
       "      <td>2905.00</td>\n",
       "      <td>3103.80</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>-118.80</td>\n",
       "      <td>-3.83</td>\n",
       "      <td>1312908</td>\n",
       "      <td>3.898444e+09</td>\n",
       "      <td>3736.40</td>\n",
       "      <td>2375.00</td>\n",
       "      <td>5.31</td>\n",
       "      <td>15.65</td>\n",
       "      <td>-0.038276</td>\n",
       "      <td>0.102743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>TATAINVEST</td>\n",
       "      <td>3437.95</td>\n",
       "      <td>3475.00</td>\n",
       "      <td>3245.55</td>\n",
       "      <td>3440.60</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>-160.60</td>\n",
       "      <td>-4.67</td>\n",
       "      <td>692221</td>\n",
       "      <td>2.307041e+09</td>\n",
       "      <td>3521.00</td>\n",
       "      <td>1730.00</td>\n",
       "      <td>34.63</td>\n",
       "      <td>46.23</td>\n",
       "      <td>-0.046678</td>\n",
       "      <td>0.127416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>HNDFDS</td>\n",
       "      <td>573.85</td>\n",
       "      <td>574.05</td>\n",
       "      <td>531.55</td>\n",
       "      <td>568.40</td>\n",
       "      <td>537.0</td>\n",
       "      <td>-31.40</td>\n",
       "      <td>-5.52</td>\n",
       "      <td>457467</td>\n",
       "      <td>2.487706e+08</td>\n",
       "      <td>749.00</td>\n",
       "      <td>405.00</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>18.09</td>\n",
       "      <td>-0.055243</td>\n",
       "      <td>0.163238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>FINCABLES</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>1216.25</td>\n",
       "      <td>1110.50</td>\n",
       "      <td>1195.55</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>-79.55</td>\n",
       "      <td>-6.65</td>\n",
       "      <td>1117926</td>\n",
       "      <td>1.289584e+09</td>\n",
       "      <td>1219.00</td>\n",
       "      <td>445.80</td>\n",
       "      <td>3.28</td>\n",
       "      <td>137.42</td>\n",
       "      <td>-0.066538</td>\n",
       "      <td>0.213084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>NAVINFLUOR</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>4000.05</td>\n",
       "      <td>3726.65</td>\n",
       "      <td>4357.65</td>\n",
       "      <td>3764.0</td>\n",
       "      <td>-593.65</td>\n",
       "      <td>-13.62</td>\n",
       "      <td>3246796</td>\n",
       "      <td>1.231825e+10</td>\n",
       "      <td>4950.00</td>\n",
       "      <td>3726.65</td>\n",
       "      <td>-18.59</td>\n",
       "      <td>-15.61</td>\n",
       "      <td>-0.136232</td>\n",
       "      <td>0.431962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SYMBOL     OPEN     HIGH      LOW  PREV. CLOSE     LTP  \\\n",
       "0    NIFTY TOTAL MARKET  9666.80  9737.90  9653.75      9633.95  9702.5   \n",
       "1             EDELWEISS    54.50    62.55    54.25        54.10    61.6   \n",
       "2               GMDCLTD   284.35   323.85   284.00       282.95   315.8   \n",
       "3              GLENMARK   783.75   861.70   782.10       776.95   854.8   \n",
       "4                ASHOKA   112.80   123.30   111.80       112.15   123.1   \n",
       "..                  ...      ...      ...      ...          ...     ...   \n",
       "747             TIINDIA  3040.00  3100.30  2905.00      3103.80  2985.0   \n",
       "748          TATAINVEST  3437.95  3475.00  3245.55      3440.60  3280.0   \n",
       "749              HNDFDS   573.85   574.05   531.55       568.40   537.0   \n",
       "750           FINCABLES  1200.00  1216.25  1110.50      1195.55  1116.0   \n",
       "751          NAVINFLUOR  4000.00  4000.05  3726.65      4357.65  3764.0   \n",
       "\n",
       "       CHNG  %CHNG  VOLUME \\n(shares)         VALUE    52W H    52W L  \\\n",
       "0     68.55   0.71         2649691885  6.231052e+11  9961.40  7145.35   \n",
       "1      7.50  13.86           45507201  2.681739e+09    77.40    35.00   \n",
       "2     32.85  11.61           23800714  7.378697e+09   323.85   122.70   \n",
       "3     77.85  10.02            9406251  7.907741e+09   880.00   368.00   \n",
       "4     10.95   9.76           17716622  2.112353e+09   123.30    70.15   \n",
       "..      ...    ...                ...           ...      ...      ...   \n",
       "747 -118.80  -3.83            1312908  3.898444e+09  3736.40  2375.00   \n",
       "748 -160.60  -4.67             692221  2.307041e+09  3521.00  1730.00   \n",
       "749  -31.40  -5.52             457467  2.487706e+08   749.00   405.00   \n",
       "750  -79.55  -6.65            1117926  1.289584e+09  1219.00   445.80   \n",
       "751 -593.65 -13.62            3246796  1.231825e+10  4950.00  3726.65   \n",
       "\n",
       "     30 D   %CHNG  365 D % CHNG \\n 29-Sep-2022  Daily Return  Volatility  \n",
       "0            1.93                        19.32      0.007115    0.000000  \n",
       "1            9.77                         4.08      0.138632    0.000000  \n",
       "2           25.78                       138.10      0.116098    0.000000  \n",
       "3           13.26                       121.06      0.100199    0.000000  \n",
       "4           20.96                        55.86      0.097637    0.000000  \n",
       "..            ...                          ...           ...         ...  \n",
       "747          5.31                        15.65     -0.038276    0.102743  \n",
       "748         34.63                        46.23     -0.046678    0.127416  \n",
       "749         -2.12                        18.09     -0.055243    0.163238  \n",
       "750          3.28                       137.42     -0.066538    0.213084  \n",
       "751        -18.59                       -15.61     -0.136232    0.431962  \n",
       "\n",
       "[752 rows x 16 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(0,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['7-Day MA'] = df['LTP'].rolling(window=7).mean()\n",
    "df['30-Day MA'] = df['LTP'].rolling(window=30).mean()\n",
    "df['50-Day MA'] = df['LTP'].rolling(window=50).mean()\n",
    "df['200-Day MA'] = df['LTP'].rolling(window=200).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>PREV. CLOSE</th>\n",
       "      <th>LTP</th>\n",
       "      <th>CHNG</th>\n",
       "      <th>%CHNG</th>\n",
       "      <th>VOLUME \\n(shares)</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>52W H</th>\n",
       "      <th>52W L</th>\n",
       "      <th>30 D   %CHNG</th>\n",
       "      <th>365 D % CHNG \\n 29-Sep-2022</th>\n",
       "      <th>Daily Return</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>7-Day MA</th>\n",
       "      <th>30-Day MA</th>\n",
       "      <th>50-Day MA</th>\n",
       "      <th>200-Day MA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIFTY TOTAL MARKET</td>\n",
       "      <td>9666.80</td>\n",
       "      <td>9737.90</td>\n",
       "      <td>9653.75</td>\n",
       "      <td>9633.95</td>\n",
       "      <td>9702.5</td>\n",
       "      <td>68.55</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2649691885</td>\n",
       "      <td>6.231052e+11</td>\n",
       "      <td>9961.40</td>\n",
       "      <td>7145.35</td>\n",
       "      <td>1.93</td>\n",
       "      <td>19.32</td>\n",
       "      <td>0.007115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDELWEISS</td>\n",
       "      <td>54.50</td>\n",
       "      <td>62.55</td>\n",
       "      <td>54.25</td>\n",
       "      <td>54.10</td>\n",
       "      <td>61.6</td>\n",
       "      <td>7.50</td>\n",
       "      <td>13.86</td>\n",
       "      <td>45507201</td>\n",
       "      <td>2.681739e+09</td>\n",
       "      <td>77.40</td>\n",
       "      <td>35.00</td>\n",
       "      <td>9.77</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.138632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GMDCLTD</td>\n",
       "      <td>284.35</td>\n",
       "      <td>323.85</td>\n",
       "      <td>284.00</td>\n",
       "      <td>282.95</td>\n",
       "      <td>315.8</td>\n",
       "      <td>32.85</td>\n",
       "      <td>11.61</td>\n",
       "      <td>23800714</td>\n",
       "      <td>7.378697e+09</td>\n",
       "      <td>323.85</td>\n",
       "      <td>122.70</td>\n",
       "      <td>25.78</td>\n",
       "      <td>138.10</td>\n",
       "      <td>0.116098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLENMARK</td>\n",
       "      <td>783.75</td>\n",
       "      <td>861.70</td>\n",
       "      <td>782.10</td>\n",
       "      <td>776.95</td>\n",
       "      <td>854.8</td>\n",
       "      <td>77.85</td>\n",
       "      <td>10.02</td>\n",
       "      <td>9406251</td>\n",
       "      <td>7.907741e+09</td>\n",
       "      <td>880.00</td>\n",
       "      <td>368.00</td>\n",
       "      <td>13.26</td>\n",
       "      <td>121.06</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHOKA</td>\n",
       "      <td>112.80</td>\n",
       "      <td>123.30</td>\n",
       "      <td>111.80</td>\n",
       "      <td>112.15</td>\n",
       "      <td>123.1</td>\n",
       "      <td>10.95</td>\n",
       "      <td>9.76</td>\n",
       "      <td>17716622</td>\n",
       "      <td>2.112353e+09</td>\n",
       "      <td>123.30</td>\n",
       "      <td>70.15</td>\n",
       "      <td>20.96</td>\n",
       "      <td>55.86</td>\n",
       "      <td>0.097637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>TIINDIA</td>\n",
       "      <td>3040.00</td>\n",
       "      <td>3100.30</td>\n",
       "      <td>2905.00</td>\n",
       "      <td>3103.80</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>-118.80</td>\n",
       "      <td>-3.83</td>\n",
       "      <td>1312908</td>\n",
       "      <td>3.898444e+09</td>\n",
       "      <td>3736.40</td>\n",
       "      <td>2375.00</td>\n",
       "      <td>5.31</td>\n",
       "      <td>15.65</td>\n",
       "      <td>-0.038276</td>\n",
       "      <td>0.102743</td>\n",
       "      <td>890.042857</td>\n",
       "      <td>1366.771667</td>\n",
       "      <td>1478.040</td>\n",
       "      <td>1980.48650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>TATAINVEST</td>\n",
       "      <td>3437.95</td>\n",
       "      <td>3475.00</td>\n",
       "      <td>3245.55</td>\n",
       "      <td>3440.60</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>-160.60</td>\n",
       "      <td>-4.67</td>\n",
       "      <td>692221</td>\n",
       "      <td>2.307041e+09</td>\n",
       "      <td>3521.00</td>\n",
       "      <td>1730.00</td>\n",
       "      <td>34.63</td>\n",
       "      <td>46.23</td>\n",
       "      <td>-0.046678</td>\n",
       "      <td>0.127416</td>\n",
       "      <td>1326.714286</td>\n",
       "      <td>1452.638333</td>\n",
       "      <td>1525.489</td>\n",
       "      <td>1984.97675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>HNDFDS</td>\n",
       "      <td>573.85</td>\n",
       "      <td>574.05</td>\n",
       "      <td>531.55</td>\n",
       "      <td>568.40</td>\n",
       "      <td>537.0</td>\n",
       "      <td>-31.40</td>\n",
       "      <td>-5.52</td>\n",
       "      <td>457467</td>\n",
       "      <td>2.487706e+08</td>\n",
       "      <td>749.00</td>\n",
       "      <td>405.00</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>18.09</td>\n",
       "      <td>-0.055243</td>\n",
       "      <td>0.163238</td>\n",
       "      <td>1328.064286</td>\n",
       "      <td>1444.571667</td>\n",
       "      <td>1526.159</td>\n",
       "      <td>1973.34650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>FINCABLES</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>1216.25</td>\n",
       "      <td>1110.50</td>\n",
       "      <td>1195.55</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>-79.55</td>\n",
       "      <td>-6.65</td>\n",
       "      <td>1117926</td>\n",
       "      <td>1.289584e+09</td>\n",
       "      <td>1219.00</td>\n",
       "      <td>445.80</td>\n",
       "      <td>3.28</td>\n",
       "      <td>137.42</td>\n",
       "      <td>-0.066538</td>\n",
       "      <td>0.213084</td>\n",
       "      <td>1336.721429</td>\n",
       "      <td>1287.271667</td>\n",
       "      <td>1542.129</td>\n",
       "      <td>1972.30250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>NAVINFLUOR</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>4000.05</td>\n",
       "      <td>3726.65</td>\n",
       "      <td>4357.65</td>\n",
       "      <td>3764.0</td>\n",
       "      <td>-593.65</td>\n",
       "      <td>-13.62</td>\n",
       "      <td>3246796</td>\n",
       "      <td>1.231825e+10</td>\n",
       "      <td>4950.00</td>\n",
       "      <td>3726.65</td>\n",
       "      <td>-18.59</td>\n",
       "      <td>-15.61</td>\n",
       "      <td>-0.136232</td>\n",
       "      <td>0.431962</td>\n",
       "      <td>1807.657143</td>\n",
       "      <td>1347.038333</td>\n",
       "      <td>1607.715</td>\n",
       "      <td>1990.68150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SYMBOL     OPEN     HIGH      LOW  PREV. CLOSE     LTP  \\\n",
       "0    NIFTY TOTAL MARKET  9666.80  9737.90  9653.75      9633.95  9702.5   \n",
       "1             EDELWEISS    54.50    62.55    54.25        54.10    61.6   \n",
       "2               GMDCLTD   284.35   323.85   284.00       282.95   315.8   \n",
       "3              GLENMARK   783.75   861.70   782.10       776.95   854.8   \n",
       "4                ASHOKA   112.80   123.30   111.80       112.15   123.1   \n",
       "..                  ...      ...      ...      ...          ...     ...   \n",
       "747             TIINDIA  3040.00  3100.30  2905.00      3103.80  2985.0   \n",
       "748          TATAINVEST  3437.95  3475.00  3245.55      3440.60  3280.0   \n",
       "749              HNDFDS   573.85   574.05   531.55       568.40   537.0   \n",
       "750           FINCABLES  1200.00  1216.25  1110.50      1195.55  1116.0   \n",
       "751          NAVINFLUOR  4000.00  4000.05  3726.65      4357.65  3764.0   \n",
       "\n",
       "       CHNG  %CHNG  VOLUME \\n(shares)         VALUE    52W H    52W L  \\\n",
       "0     68.55   0.71         2649691885  6.231052e+11  9961.40  7145.35   \n",
       "1      7.50  13.86           45507201  2.681739e+09    77.40    35.00   \n",
       "2     32.85  11.61           23800714  7.378697e+09   323.85   122.70   \n",
       "3     77.85  10.02            9406251  7.907741e+09   880.00   368.00   \n",
       "4     10.95   9.76           17716622  2.112353e+09   123.30    70.15   \n",
       "..      ...    ...                ...           ...      ...      ...   \n",
       "747 -118.80  -3.83            1312908  3.898444e+09  3736.40  2375.00   \n",
       "748 -160.60  -4.67             692221  2.307041e+09  3521.00  1730.00   \n",
       "749  -31.40  -5.52             457467  2.487706e+08   749.00   405.00   \n",
       "750  -79.55  -6.65            1117926  1.289584e+09  1219.00   445.80   \n",
       "751 -593.65 -13.62            3246796  1.231825e+10  4950.00  3726.65   \n",
       "\n",
       "     30 D   %CHNG  365 D % CHNG \\n 29-Sep-2022  Daily Return  Volatility  \\\n",
       "0            1.93                        19.32      0.007115    0.000000   \n",
       "1            9.77                         4.08      0.138632    0.000000   \n",
       "2           25.78                       138.10      0.116098    0.000000   \n",
       "3           13.26                       121.06      0.100199    0.000000   \n",
       "4           20.96                        55.86      0.097637    0.000000   \n",
       "..            ...                          ...           ...         ...   \n",
       "747          5.31                        15.65     -0.038276    0.102743   \n",
       "748         34.63                        46.23     -0.046678    0.127416   \n",
       "749         -2.12                        18.09     -0.055243    0.163238   \n",
       "750          3.28                       137.42     -0.066538    0.213084   \n",
       "751        -18.59                       -15.61     -0.136232    0.431962   \n",
       "\n",
       "        7-Day MA    30-Day MA  50-Day MA  200-Day MA  \n",
       "0            NaN          NaN        NaN         NaN  \n",
       "1            NaN          NaN        NaN         NaN  \n",
       "2            NaN          NaN        NaN         NaN  \n",
       "3            NaN          NaN        NaN         NaN  \n",
       "4            NaN          NaN        NaN         NaN  \n",
       "..           ...          ...        ...         ...  \n",
       "747   890.042857  1366.771667   1478.040  1980.48650  \n",
       "748  1326.714286  1452.638333   1525.489  1984.97675  \n",
       "749  1328.064286  1444.571667   1526.159  1973.34650  \n",
       "750  1336.721429  1287.271667   1542.129  1972.30250  \n",
       "751  1807.657143  1347.038333   1607.715  1990.68150  \n",
       "\n",
       "[752 rows x 20 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rsi(data, period=14):\n",
    "    delta = data['LTP'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=period).mean()\n",
    "    avg_loss = loss.rolling(window=period).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "df['RSI'] = calculate_rsi(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>PREV. CLOSE</th>\n",
       "      <th>LTP</th>\n",
       "      <th>CHNG</th>\n",
       "      <th>%CHNG</th>\n",
       "      <th>VOLUME \\n(shares)</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>...</th>\n",
       "      <th>52W L</th>\n",
       "      <th>30 D   %CHNG</th>\n",
       "      <th>365 D % CHNG \\n 29-Sep-2022</th>\n",
       "      <th>Daily Return</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>7-Day MA</th>\n",
       "      <th>30-Day MA</th>\n",
       "      <th>50-Day MA</th>\n",
       "      <th>200-Day MA</th>\n",
       "      <th>RSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIFTY TOTAL MARKET</td>\n",
       "      <td>9666.80</td>\n",
       "      <td>9737.90</td>\n",
       "      <td>9653.75</td>\n",
       "      <td>9633.95</td>\n",
       "      <td>9702.5</td>\n",
       "      <td>68.55</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2649691885</td>\n",
       "      <td>6.231052e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>7145.35</td>\n",
       "      <td>1.93</td>\n",
       "      <td>19.32</td>\n",
       "      <td>0.007115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDELWEISS</td>\n",
       "      <td>54.50</td>\n",
       "      <td>62.55</td>\n",
       "      <td>54.25</td>\n",
       "      <td>54.10</td>\n",
       "      <td>61.6</td>\n",
       "      <td>7.50</td>\n",
       "      <td>13.86</td>\n",
       "      <td>45507201</td>\n",
       "      <td>2.681739e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>35.00</td>\n",
       "      <td>9.77</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.138632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GMDCLTD</td>\n",
       "      <td>284.35</td>\n",
       "      <td>323.85</td>\n",
       "      <td>284.00</td>\n",
       "      <td>282.95</td>\n",
       "      <td>315.8</td>\n",
       "      <td>32.85</td>\n",
       "      <td>11.61</td>\n",
       "      <td>23800714</td>\n",
       "      <td>7.378697e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>122.70</td>\n",
       "      <td>25.78</td>\n",
       "      <td>138.10</td>\n",
       "      <td>0.116098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLENMARK</td>\n",
       "      <td>783.75</td>\n",
       "      <td>861.70</td>\n",
       "      <td>782.10</td>\n",
       "      <td>776.95</td>\n",
       "      <td>854.8</td>\n",
       "      <td>77.85</td>\n",
       "      <td>10.02</td>\n",
       "      <td>9406251</td>\n",
       "      <td>7.907741e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>368.00</td>\n",
       "      <td>13.26</td>\n",
       "      <td>121.06</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHOKA</td>\n",
       "      <td>112.80</td>\n",
       "      <td>123.30</td>\n",
       "      <td>111.80</td>\n",
       "      <td>112.15</td>\n",
       "      <td>123.1</td>\n",
       "      <td>10.95</td>\n",
       "      <td>9.76</td>\n",
       "      <td>17716622</td>\n",
       "      <td>2.112353e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>70.15</td>\n",
       "      <td>20.96</td>\n",
       "      <td>55.86</td>\n",
       "      <td>0.097637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>TIINDIA</td>\n",
       "      <td>3040.00</td>\n",
       "      <td>3100.30</td>\n",
       "      <td>2905.00</td>\n",
       "      <td>3103.80</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>-118.80</td>\n",
       "      <td>-3.83</td>\n",
       "      <td>1312908</td>\n",
       "      <td>3.898444e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>2375.00</td>\n",
       "      <td>5.31</td>\n",
       "      <td>15.65</td>\n",
       "      <td>-0.038276</td>\n",
       "      <td>0.102743</td>\n",
       "      <td>890.042857</td>\n",
       "      <td>1366.771667</td>\n",
       "      <td>1478.040</td>\n",
       "      <td>1980.48650</td>\n",
       "      <td>57.494902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>TATAINVEST</td>\n",
       "      <td>3437.95</td>\n",
       "      <td>3475.00</td>\n",
       "      <td>3245.55</td>\n",
       "      <td>3440.60</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>-160.60</td>\n",
       "      <td>-4.67</td>\n",
       "      <td>692221</td>\n",
       "      <td>2.307041e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>1730.00</td>\n",
       "      <td>34.63</td>\n",
       "      <td>46.23</td>\n",
       "      <td>-0.046678</td>\n",
       "      <td>0.127416</td>\n",
       "      <td>1326.714286</td>\n",
       "      <td>1452.638333</td>\n",
       "      <td>1525.489</td>\n",
       "      <td>1984.97675</td>\n",
       "      <td>58.385272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>HNDFDS</td>\n",
       "      <td>573.85</td>\n",
       "      <td>574.05</td>\n",
       "      <td>531.55</td>\n",
       "      <td>568.40</td>\n",
       "      <td>537.0</td>\n",
       "      <td>-31.40</td>\n",
       "      <td>-5.52</td>\n",
       "      <td>457467</td>\n",
       "      <td>2.487706e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>405.00</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>18.09</td>\n",
       "      <td>-0.055243</td>\n",
       "      <td>0.163238</td>\n",
       "      <td>1328.064286</td>\n",
       "      <td>1444.571667</td>\n",
       "      <td>1526.159</td>\n",
       "      <td>1973.34650</td>\n",
       "      <td>50.373904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>FINCABLES</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>1216.25</td>\n",
       "      <td>1110.50</td>\n",
       "      <td>1195.55</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>-79.55</td>\n",
       "      <td>-6.65</td>\n",
       "      <td>1117926</td>\n",
       "      <td>1.289584e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>445.80</td>\n",
       "      <td>3.28</td>\n",
       "      <td>137.42</td>\n",
       "      <td>-0.066538</td>\n",
       "      <td>0.213084</td>\n",
       "      <td>1336.721429</td>\n",
       "      <td>1287.271667</td>\n",
       "      <td>1542.129</td>\n",
       "      <td>1972.30250</td>\n",
       "      <td>52.329102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>NAVINFLUOR</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>4000.05</td>\n",
       "      <td>3726.65</td>\n",
       "      <td>4357.65</td>\n",
       "      <td>3764.0</td>\n",
       "      <td>-593.65</td>\n",
       "      <td>-13.62</td>\n",
       "      <td>3246796</td>\n",
       "      <td>1.231825e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>3726.65</td>\n",
       "      <td>-18.59</td>\n",
       "      <td>-15.61</td>\n",
       "      <td>-0.136232</td>\n",
       "      <td>0.431962</td>\n",
       "      <td>1807.657143</td>\n",
       "      <td>1347.038333</td>\n",
       "      <td>1607.715</td>\n",
       "      <td>1990.68150</td>\n",
       "      <td>53.228897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SYMBOL     OPEN     HIGH      LOW  PREV. CLOSE     LTP  \\\n",
       "0    NIFTY TOTAL MARKET  9666.80  9737.90  9653.75      9633.95  9702.5   \n",
       "1             EDELWEISS    54.50    62.55    54.25        54.10    61.6   \n",
       "2               GMDCLTD   284.35   323.85   284.00       282.95   315.8   \n",
       "3              GLENMARK   783.75   861.70   782.10       776.95   854.8   \n",
       "4                ASHOKA   112.80   123.30   111.80       112.15   123.1   \n",
       "..                  ...      ...      ...      ...          ...     ...   \n",
       "747             TIINDIA  3040.00  3100.30  2905.00      3103.80  2985.0   \n",
       "748          TATAINVEST  3437.95  3475.00  3245.55      3440.60  3280.0   \n",
       "749              HNDFDS   573.85   574.05   531.55       568.40   537.0   \n",
       "750           FINCABLES  1200.00  1216.25  1110.50      1195.55  1116.0   \n",
       "751          NAVINFLUOR  4000.00  4000.05  3726.65      4357.65  3764.0   \n",
       "\n",
       "       CHNG  %CHNG  VOLUME \\n(shares)         VALUE  ...    52W L  \\\n",
       "0     68.55   0.71         2649691885  6.231052e+11  ...  7145.35   \n",
       "1      7.50  13.86           45507201  2.681739e+09  ...    35.00   \n",
       "2     32.85  11.61           23800714  7.378697e+09  ...   122.70   \n",
       "3     77.85  10.02            9406251  7.907741e+09  ...   368.00   \n",
       "4     10.95   9.76           17716622  2.112353e+09  ...    70.15   \n",
       "..      ...    ...                ...           ...  ...      ...   \n",
       "747 -118.80  -3.83            1312908  3.898444e+09  ...  2375.00   \n",
       "748 -160.60  -4.67             692221  2.307041e+09  ...  1730.00   \n",
       "749  -31.40  -5.52             457467  2.487706e+08  ...   405.00   \n",
       "750  -79.55  -6.65            1117926  1.289584e+09  ...   445.80   \n",
       "751 -593.65 -13.62            3246796  1.231825e+10  ...  3726.65   \n",
       "\n",
       "     30 D   %CHNG  365 D % CHNG \\n 29-Sep-2022  Daily Return  Volatility  \\\n",
       "0            1.93                        19.32      0.007115    0.000000   \n",
       "1            9.77                         4.08      0.138632    0.000000   \n",
       "2           25.78                       138.10      0.116098    0.000000   \n",
       "3           13.26                       121.06      0.100199    0.000000   \n",
       "4           20.96                        55.86      0.097637    0.000000   \n",
       "..            ...                          ...           ...         ...   \n",
       "747          5.31                        15.65     -0.038276    0.102743   \n",
       "748         34.63                        46.23     -0.046678    0.127416   \n",
       "749         -2.12                        18.09     -0.055243    0.163238   \n",
       "750          3.28                       137.42     -0.066538    0.213084   \n",
       "751        -18.59                       -15.61     -0.136232    0.431962   \n",
       "\n",
       "        7-Day MA    30-Day MA  50-Day MA  200-Day MA        RSI  \n",
       "0            NaN          NaN        NaN         NaN        NaN  \n",
       "1            NaN          NaN        NaN         NaN        NaN  \n",
       "2            NaN          NaN        NaN         NaN        NaN  \n",
       "3            NaN          NaN        NaN         NaN        NaN  \n",
       "4            NaN          NaN        NaN         NaN        NaN  \n",
       "..           ...          ...        ...         ...        ...  \n",
       "747   890.042857  1366.771667   1478.040  1980.48650  57.494902  \n",
       "748  1326.714286  1452.638333   1525.489  1984.97675  58.385272  \n",
       "749  1328.064286  1444.571667   1526.159  1973.34650  50.373904  \n",
       "750  1336.721429  1287.271667   1542.129  1972.30250  52.329102  \n",
       "751  1807.657143  1347.038333   1607.715  1990.68150  53.228897  \n",
       "\n",
       "[752 rows x 21 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bid-Ask Spread'] = (df['HIGH'] - df['LOW']) / df['LTP']\n",
    "df['Volume Ratio'] = df['VOLUME \\n(shares)'] / df['VALUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>PREV. CLOSE</th>\n",
       "      <th>LTP</th>\n",
       "      <th>CHNG</th>\n",
       "      <th>%CHNG</th>\n",
       "      <th>VOLUME \\n(shares)</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>...</th>\n",
       "      <th>365 D % CHNG \\n 29-Sep-2022</th>\n",
       "      <th>Daily Return</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>7-Day MA</th>\n",
       "      <th>30-Day MA</th>\n",
       "      <th>50-Day MA</th>\n",
       "      <th>200-Day MA</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Bid-Ask Spread</th>\n",
       "      <th>Volume Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIFTY TOTAL MARKET</td>\n",
       "      <td>9666.80</td>\n",
       "      <td>9737.90</td>\n",
       "      <td>9653.75</td>\n",
       "      <td>9633.95</td>\n",
       "      <td>9702.5</td>\n",
       "      <td>68.55</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2649691885</td>\n",
       "      <td>6.231052e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>19.32</td>\n",
       "      <td>0.007115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008673</td>\n",
       "      <td>0.004252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDELWEISS</td>\n",
       "      <td>54.50</td>\n",
       "      <td>62.55</td>\n",
       "      <td>54.25</td>\n",
       "      <td>54.10</td>\n",
       "      <td>61.6</td>\n",
       "      <td>7.50</td>\n",
       "      <td>13.86</td>\n",
       "      <td>45507201</td>\n",
       "      <td>2.681739e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.138632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.134740</td>\n",
       "      <td>0.016969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GMDCLTD</td>\n",
       "      <td>284.35</td>\n",
       "      <td>323.85</td>\n",
       "      <td>284.00</td>\n",
       "      <td>282.95</td>\n",
       "      <td>315.8</td>\n",
       "      <td>32.85</td>\n",
       "      <td>11.61</td>\n",
       "      <td>23800714</td>\n",
       "      <td>7.378697e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>138.10</td>\n",
       "      <td>0.116098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.126187</td>\n",
       "      <td>0.003226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLENMARK</td>\n",
       "      <td>783.75</td>\n",
       "      <td>861.70</td>\n",
       "      <td>782.10</td>\n",
       "      <td>776.95</td>\n",
       "      <td>854.8</td>\n",
       "      <td>77.85</td>\n",
       "      <td>10.02</td>\n",
       "      <td>9406251</td>\n",
       "      <td>7.907741e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>121.06</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093121</td>\n",
       "      <td>0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHOKA</td>\n",
       "      <td>112.80</td>\n",
       "      <td>123.30</td>\n",
       "      <td>111.80</td>\n",
       "      <td>112.15</td>\n",
       "      <td>123.1</td>\n",
       "      <td>10.95</td>\n",
       "      <td>9.76</td>\n",
       "      <td>17716622</td>\n",
       "      <td>2.112353e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>55.86</td>\n",
       "      <td>0.097637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>0.008387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>TIINDIA</td>\n",
       "      <td>3040.00</td>\n",
       "      <td>3100.30</td>\n",
       "      <td>2905.00</td>\n",
       "      <td>3103.80</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>-118.80</td>\n",
       "      <td>-3.83</td>\n",
       "      <td>1312908</td>\n",
       "      <td>3.898444e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>15.65</td>\n",
       "      <td>-0.038276</td>\n",
       "      <td>0.102743</td>\n",
       "      <td>890.042857</td>\n",
       "      <td>1366.771667</td>\n",
       "      <td>1478.040</td>\n",
       "      <td>1980.48650</td>\n",
       "      <td>57.494902</td>\n",
       "      <td>0.065427</td>\n",
       "      <td>0.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>TATAINVEST</td>\n",
       "      <td>3437.95</td>\n",
       "      <td>3475.00</td>\n",
       "      <td>3245.55</td>\n",
       "      <td>3440.60</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>-160.60</td>\n",
       "      <td>-4.67</td>\n",
       "      <td>692221</td>\n",
       "      <td>2.307041e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>46.23</td>\n",
       "      <td>-0.046678</td>\n",
       "      <td>0.127416</td>\n",
       "      <td>1326.714286</td>\n",
       "      <td>1452.638333</td>\n",
       "      <td>1525.489</td>\n",
       "      <td>1984.97675</td>\n",
       "      <td>58.385272</td>\n",
       "      <td>0.069954</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>HNDFDS</td>\n",
       "      <td>573.85</td>\n",
       "      <td>574.05</td>\n",
       "      <td>531.55</td>\n",
       "      <td>568.40</td>\n",
       "      <td>537.0</td>\n",
       "      <td>-31.40</td>\n",
       "      <td>-5.52</td>\n",
       "      <td>457467</td>\n",
       "      <td>2.487706e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>18.09</td>\n",
       "      <td>-0.055243</td>\n",
       "      <td>0.163238</td>\n",
       "      <td>1328.064286</td>\n",
       "      <td>1444.571667</td>\n",
       "      <td>1526.159</td>\n",
       "      <td>1973.34650</td>\n",
       "      <td>50.373904</td>\n",
       "      <td>0.079143</td>\n",
       "      <td>0.001839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>FINCABLES</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>1216.25</td>\n",
       "      <td>1110.50</td>\n",
       "      <td>1195.55</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>-79.55</td>\n",
       "      <td>-6.65</td>\n",
       "      <td>1117926</td>\n",
       "      <td>1.289584e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>137.42</td>\n",
       "      <td>-0.066538</td>\n",
       "      <td>0.213084</td>\n",
       "      <td>1336.721429</td>\n",
       "      <td>1287.271667</td>\n",
       "      <td>1542.129</td>\n",
       "      <td>1972.30250</td>\n",
       "      <td>52.329102</td>\n",
       "      <td>0.094758</td>\n",
       "      <td>0.000867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>NAVINFLUOR</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>4000.05</td>\n",
       "      <td>3726.65</td>\n",
       "      <td>4357.65</td>\n",
       "      <td>3764.0</td>\n",
       "      <td>-593.65</td>\n",
       "      <td>-13.62</td>\n",
       "      <td>3246796</td>\n",
       "      <td>1.231825e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.61</td>\n",
       "      <td>-0.136232</td>\n",
       "      <td>0.431962</td>\n",
       "      <td>1807.657143</td>\n",
       "      <td>1347.038333</td>\n",
       "      <td>1607.715</td>\n",
       "      <td>1990.68150</td>\n",
       "      <td>53.228897</td>\n",
       "      <td>0.072635</td>\n",
       "      <td>0.000264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SYMBOL     OPEN     HIGH      LOW  PREV. CLOSE     LTP  \\\n",
       "0    NIFTY TOTAL MARKET  9666.80  9737.90  9653.75      9633.95  9702.5   \n",
       "1             EDELWEISS    54.50    62.55    54.25        54.10    61.6   \n",
       "2               GMDCLTD   284.35   323.85   284.00       282.95   315.8   \n",
       "3              GLENMARK   783.75   861.70   782.10       776.95   854.8   \n",
       "4                ASHOKA   112.80   123.30   111.80       112.15   123.1   \n",
       "..                  ...      ...      ...      ...          ...     ...   \n",
       "747             TIINDIA  3040.00  3100.30  2905.00      3103.80  2985.0   \n",
       "748          TATAINVEST  3437.95  3475.00  3245.55      3440.60  3280.0   \n",
       "749              HNDFDS   573.85   574.05   531.55       568.40   537.0   \n",
       "750           FINCABLES  1200.00  1216.25  1110.50      1195.55  1116.0   \n",
       "751          NAVINFLUOR  4000.00  4000.05  3726.65      4357.65  3764.0   \n",
       "\n",
       "       CHNG  %CHNG  VOLUME \\n(shares)         VALUE  ...  \\\n",
       "0     68.55   0.71         2649691885  6.231052e+11  ...   \n",
       "1      7.50  13.86           45507201  2.681739e+09  ...   \n",
       "2     32.85  11.61           23800714  7.378697e+09  ...   \n",
       "3     77.85  10.02            9406251  7.907741e+09  ...   \n",
       "4     10.95   9.76           17716622  2.112353e+09  ...   \n",
       "..      ...    ...                ...           ...  ...   \n",
       "747 -118.80  -3.83            1312908  3.898444e+09  ...   \n",
       "748 -160.60  -4.67             692221  2.307041e+09  ...   \n",
       "749  -31.40  -5.52             457467  2.487706e+08  ...   \n",
       "750  -79.55  -6.65            1117926  1.289584e+09  ...   \n",
       "751 -593.65 -13.62            3246796  1.231825e+10  ...   \n",
       "\n",
       "     365 D % CHNG \\n 29-Sep-2022  Daily Return  Volatility     7-Day MA  \\\n",
       "0                          19.32      0.007115    0.000000          NaN   \n",
       "1                           4.08      0.138632    0.000000          NaN   \n",
       "2                         138.10      0.116098    0.000000          NaN   \n",
       "3                         121.06      0.100199    0.000000          NaN   \n",
       "4                          55.86      0.097637    0.000000          NaN   \n",
       "..                           ...           ...         ...          ...   \n",
       "747                        15.65     -0.038276    0.102743   890.042857   \n",
       "748                        46.23     -0.046678    0.127416  1326.714286   \n",
       "749                        18.09     -0.055243    0.163238  1328.064286   \n",
       "750                       137.42     -0.066538    0.213084  1336.721429   \n",
       "751                       -15.61     -0.136232    0.431962  1807.657143   \n",
       "\n",
       "       30-Day MA  50-Day MA  200-Day MA        RSI  Bid-Ask Spread  \\\n",
       "0            NaN        NaN         NaN        NaN        0.008673   \n",
       "1            NaN        NaN         NaN        NaN        0.134740   \n",
       "2            NaN        NaN         NaN        NaN        0.126187   \n",
       "3            NaN        NaN         NaN        NaN        0.093121   \n",
       "4            NaN        NaN         NaN        NaN        0.093420   \n",
       "..           ...        ...         ...        ...             ...   \n",
       "747  1366.771667   1478.040  1980.48650  57.494902        0.065427   \n",
       "748  1452.638333   1525.489  1984.97675  58.385272        0.069954   \n",
       "749  1444.571667   1526.159  1973.34650  50.373904        0.079143   \n",
       "750  1287.271667   1542.129  1972.30250  52.329102        0.094758   \n",
       "751  1347.038333   1607.715  1990.68150  53.228897        0.072635   \n",
       "\n",
       "     Volume Ratio  \n",
       "0        0.004252  \n",
       "1        0.016969  \n",
       "2        0.003226  \n",
       "3        0.001189  \n",
       "4        0.008387  \n",
       "..            ...  \n",
       "747      0.000337  \n",
       "748      0.000300  \n",
       "749      0.001839  \n",
       "750      0.000867  \n",
       "751      0.000264  \n",
       "\n",
       "[752 rows x 23 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>PREV. CLOSE</th>\n",
       "      <th>LTP</th>\n",
       "      <th>CHNG</th>\n",
       "      <th>%CHNG</th>\n",
       "      <th>VOLUME \\n(shares)</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>...</th>\n",
       "      <th>365 D % CHNG \\n 29-Sep-2022</th>\n",
       "      <th>Daily Return</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>7-Day MA</th>\n",
       "      <th>30-Day MA</th>\n",
       "      <th>50-Day MA</th>\n",
       "      <th>200-Day MA</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Bid-Ask Spread</th>\n",
       "      <th>Volume Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIFTY TOTAL MARKET</td>\n",
       "      <td>9666.80</td>\n",
       "      <td>9737.90</td>\n",
       "      <td>9653.75</td>\n",
       "      <td>9633.95</td>\n",
       "      <td>9702.5</td>\n",
       "      <td>68.55</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2649691885</td>\n",
       "      <td>6.231052e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>19.32</td>\n",
       "      <td>0.007115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008673</td>\n",
       "      <td>0.004252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDELWEISS</td>\n",
       "      <td>54.50</td>\n",
       "      <td>62.55</td>\n",
       "      <td>54.25</td>\n",
       "      <td>54.10</td>\n",
       "      <td>61.6</td>\n",
       "      <td>7.50</td>\n",
       "      <td>13.86</td>\n",
       "      <td>45507201</td>\n",
       "      <td>2.681739e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.138632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134740</td>\n",
       "      <td>0.016969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GMDCLTD</td>\n",
       "      <td>284.35</td>\n",
       "      <td>323.85</td>\n",
       "      <td>284.00</td>\n",
       "      <td>282.95</td>\n",
       "      <td>315.8</td>\n",
       "      <td>32.85</td>\n",
       "      <td>11.61</td>\n",
       "      <td>23800714</td>\n",
       "      <td>7.378697e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>138.10</td>\n",
       "      <td>0.116098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126187</td>\n",
       "      <td>0.003226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLENMARK</td>\n",
       "      <td>783.75</td>\n",
       "      <td>861.70</td>\n",
       "      <td>782.10</td>\n",
       "      <td>776.95</td>\n",
       "      <td>854.8</td>\n",
       "      <td>77.85</td>\n",
       "      <td>10.02</td>\n",
       "      <td>9406251</td>\n",
       "      <td>7.907741e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>121.06</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093121</td>\n",
       "      <td>0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHOKA</td>\n",
       "      <td>112.80</td>\n",
       "      <td>123.30</td>\n",
       "      <td>111.80</td>\n",
       "      <td>112.15</td>\n",
       "      <td>123.1</td>\n",
       "      <td>10.95</td>\n",
       "      <td>9.76</td>\n",
       "      <td>17716622</td>\n",
       "      <td>2.112353e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>55.86</td>\n",
       "      <td>0.097637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>0.008387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>TIINDIA</td>\n",
       "      <td>3040.00</td>\n",
       "      <td>3100.30</td>\n",
       "      <td>2905.00</td>\n",
       "      <td>3103.80</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>-118.80</td>\n",
       "      <td>-3.83</td>\n",
       "      <td>1312908</td>\n",
       "      <td>3.898444e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>15.65</td>\n",
       "      <td>-0.038276</td>\n",
       "      <td>0.102743</td>\n",
       "      <td>890.042857</td>\n",
       "      <td>1366.771667</td>\n",
       "      <td>1478.040</td>\n",
       "      <td>1980.48650</td>\n",
       "      <td>57.494902</td>\n",
       "      <td>0.065427</td>\n",
       "      <td>0.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>TATAINVEST</td>\n",
       "      <td>3437.95</td>\n",
       "      <td>3475.00</td>\n",
       "      <td>3245.55</td>\n",
       "      <td>3440.60</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>-160.60</td>\n",
       "      <td>-4.67</td>\n",
       "      <td>692221</td>\n",
       "      <td>2.307041e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>46.23</td>\n",
       "      <td>-0.046678</td>\n",
       "      <td>0.127416</td>\n",
       "      <td>1326.714286</td>\n",
       "      <td>1452.638333</td>\n",
       "      <td>1525.489</td>\n",
       "      <td>1984.97675</td>\n",
       "      <td>58.385272</td>\n",
       "      <td>0.069954</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>HNDFDS</td>\n",
       "      <td>573.85</td>\n",
       "      <td>574.05</td>\n",
       "      <td>531.55</td>\n",
       "      <td>568.40</td>\n",
       "      <td>537.0</td>\n",
       "      <td>-31.40</td>\n",
       "      <td>-5.52</td>\n",
       "      <td>457467</td>\n",
       "      <td>2.487706e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>18.09</td>\n",
       "      <td>-0.055243</td>\n",
       "      <td>0.163238</td>\n",
       "      <td>1328.064286</td>\n",
       "      <td>1444.571667</td>\n",
       "      <td>1526.159</td>\n",
       "      <td>1973.34650</td>\n",
       "      <td>50.373904</td>\n",
       "      <td>0.079143</td>\n",
       "      <td>0.001839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>FINCABLES</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>1216.25</td>\n",
       "      <td>1110.50</td>\n",
       "      <td>1195.55</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>-79.55</td>\n",
       "      <td>-6.65</td>\n",
       "      <td>1117926</td>\n",
       "      <td>1.289584e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>137.42</td>\n",
       "      <td>-0.066538</td>\n",
       "      <td>0.213084</td>\n",
       "      <td>1336.721429</td>\n",
       "      <td>1287.271667</td>\n",
       "      <td>1542.129</td>\n",
       "      <td>1972.30250</td>\n",
       "      <td>52.329102</td>\n",
       "      <td>0.094758</td>\n",
       "      <td>0.000867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>NAVINFLUOR</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>4000.05</td>\n",
       "      <td>3726.65</td>\n",
       "      <td>4357.65</td>\n",
       "      <td>3764.0</td>\n",
       "      <td>-593.65</td>\n",
       "      <td>-13.62</td>\n",
       "      <td>3246796</td>\n",
       "      <td>1.231825e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.61</td>\n",
       "      <td>-0.136232</td>\n",
       "      <td>0.431962</td>\n",
       "      <td>1807.657143</td>\n",
       "      <td>1347.038333</td>\n",
       "      <td>1607.715</td>\n",
       "      <td>1990.68150</td>\n",
       "      <td>53.228897</td>\n",
       "      <td>0.072635</td>\n",
       "      <td>0.000264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SYMBOL     OPEN     HIGH      LOW  PREV. CLOSE     LTP  \\\n",
       "0    NIFTY TOTAL MARKET  9666.80  9737.90  9653.75      9633.95  9702.5   \n",
       "1             EDELWEISS    54.50    62.55    54.25        54.10    61.6   \n",
       "2               GMDCLTD   284.35   323.85   284.00       282.95   315.8   \n",
       "3              GLENMARK   783.75   861.70   782.10       776.95   854.8   \n",
       "4                ASHOKA   112.80   123.30   111.80       112.15   123.1   \n",
       "..                  ...      ...      ...      ...          ...     ...   \n",
       "747             TIINDIA  3040.00  3100.30  2905.00      3103.80  2985.0   \n",
       "748          TATAINVEST  3437.95  3475.00  3245.55      3440.60  3280.0   \n",
       "749              HNDFDS   573.85   574.05   531.55       568.40   537.0   \n",
       "750           FINCABLES  1200.00  1216.25  1110.50      1195.55  1116.0   \n",
       "751          NAVINFLUOR  4000.00  4000.05  3726.65      4357.65  3764.0   \n",
       "\n",
       "       CHNG  %CHNG  VOLUME \\n(shares)         VALUE  ...  \\\n",
       "0     68.55   0.71         2649691885  6.231052e+11  ...   \n",
       "1      7.50  13.86           45507201  2.681739e+09  ...   \n",
       "2     32.85  11.61           23800714  7.378697e+09  ...   \n",
       "3     77.85  10.02            9406251  7.907741e+09  ...   \n",
       "4     10.95   9.76           17716622  2.112353e+09  ...   \n",
       "..      ...    ...                ...           ...  ...   \n",
       "747 -118.80  -3.83            1312908  3.898444e+09  ...   \n",
       "748 -160.60  -4.67             692221  2.307041e+09  ...   \n",
       "749  -31.40  -5.52             457467  2.487706e+08  ...   \n",
       "750  -79.55  -6.65            1117926  1.289584e+09  ...   \n",
       "751 -593.65 -13.62            3246796  1.231825e+10  ...   \n",
       "\n",
       "     365 D % CHNG \\n 29-Sep-2022  Daily Return  Volatility     7-Day MA  \\\n",
       "0                          19.32      0.007115    0.000000     0.000000   \n",
       "1                           4.08      0.138632    0.000000     0.000000   \n",
       "2                         138.10      0.116098    0.000000     0.000000   \n",
       "3                         121.06      0.100199    0.000000     0.000000   \n",
       "4                          55.86      0.097637    0.000000     0.000000   \n",
       "..                           ...           ...         ...          ...   \n",
       "747                        15.65     -0.038276    0.102743   890.042857   \n",
       "748                        46.23     -0.046678    0.127416  1326.714286   \n",
       "749                        18.09     -0.055243    0.163238  1328.064286   \n",
       "750                       137.42     -0.066538    0.213084  1336.721429   \n",
       "751                       -15.61     -0.136232    0.431962  1807.657143   \n",
       "\n",
       "       30-Day MA  50-Day MA  200-Day MA        RSI  Bid-Ask Spread  \\\n",
       "0       0.000000      0.000     0.00000   0.000000        0.008673   \n",
       "1       0.000000      0.000     0.00000   0.000000        0.134740   \n",
       "2       0.000000      0.000     0.00000   0.000000        0.126187   \n",
       "3       0.000000      0.000     0.00000   0.000000        0.093121   \n",
       "4       0.000000      0.000     0.00000   0.000000        0.093420   \n",
       "..           ...        ...         ...        ...             ...   \n",
       "747  1366.771667   1478.040  1980.48650  57.494902        0.065427   \n",
       "748  1452.638333   1525.489  1984.97675  58.385272        0.069954   \n",
       "749  1444.571667   1526.159  1973.34650  50.373904        0.079143   \n",
       "750  1287.271667   1542.129  1972.30250  52.329102        0.094758   \n",
       "751  1347.038333   1607.715  1990.68150  53.228897        0.072635   \n",
       "\n",
       "     Volume Ratio  \n",
       "0        0.004252  \n",
       "1        0.016969  \n",
       "2        0.003226  \n",
       "3        0.001189  \n",
       "4        0.008387  \n",
       "..            ...  \n",
       "747      0.000337  \n",
       "748      0.000300  \n",
       "749      0.001839  \n",
       "750      0.000867  \n",
       "751      0.000264  \n",
       "\n",
       "[752 rows x 23 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(0,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SYMBOL', 'OPEN', 'HIGH', 'LOW', 'PREV. CLOSE', 'LTP', 'CHNG', '%CHNG',\n",
       "       'VOLUME \\n(shares)', 'VALUE', '52W H', '52W L', '30 D   %CHNG',\n",
       "       '365 D % CHNG \\n 29-Sep-2022', 'Daily Return', 'Volatility', '7-Day MA',\n",
       "       '30-Day MA', '50-Day MA', '200-Day MA', 'RSI', 'Bid-Ask Spread',\n",
       "       'Volume Ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to categorize risk based on user risk level\n",
    "def categorize_risk(volatility):\n",
    "    if volatility <= 0.20:\n",
    "        return 'Low Risk'\n",
    "    elif 0.20 < volatility <= 0.30:\n",
    "        return 'Medium Risk'\n",
    "    elif 0.30 < volatility :\n",
    "        return 'High Risk'\n",
    "    else:\n",
    "        return 'Invalid'\n",
    "\n",
    "# Apply the risk assessment function to each row in the DataFrame\n",
    "df['Risk Category'] = df['Volatility'].apply(categorize_risk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>PREV. CLOSE</th>\n",
       "      <th>LTP</th>\n",
       "      <th>CHNG</th>\n",
       "      <th>%CHNG</th>\n",
       "      <th>VOLUME \\n(shares)</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>...</th>\n",
       "      <th>Daily Return</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>7-Day MA</th>\n",
       "      <th>30-Day MA</th>\n",
       "      <th>50-Day MA</th>\n",
       "      <th>200-Day MA</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Bid-Ask Spread</th>\n",
       "      <th>Volume Ratio</th>\n",
       "      <th>Risk Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIFTY TOTAL MARKET</td>\n",
       "      <td>9666.80</td>\n",
       "      <td>9737.90</td>\n",
       "      <td>9653.75</td>\n",
       "      <td>9633.95</td>\n",
       "      <td>9702.5</td>\n",
       "      <td>68.55</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2649691885</td>\n",
       "      <td>6.231052e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008673</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDELWEISS</td>\n",
       "      <td>54.50</td>\n",
       "      <td>62.55</td>\n",
       "      <td>54.25</td>\n",
       "      <td>54.10</td>\n",
       "      <td>61.6</td>\n",
       "      <td>7.50</td>\n",
       "      <td>13.86</td>\n",
       "      <td>45507201</td>\n",
       "      <td>2.681739e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134740</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GMDCLTD</td>\n",
       "      <td>284.35</td>\n",
       "      <td>323.85</td>\n",
       "      <td>284.00</td>\n",
       "      <td>282.95</td>\n",
       "      <td>315.8</td>\n",
       "      <td>32.85</td>\n",
       "      <td>11.61</td>\n",
       "      <td>23800714</td>\n",
       "      <td>7.378697e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126187</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLENMARK</td>\n",
       "      <td>783.75</td>\n",
       "      <td>861.70</td>\n",
       "      <td>782.10</td>\n",
       "      <td>776.95</td>\n",
       "      <td>854.8</td>\n",
       "      <td>77.85</td>\n",
       "      <td>10.02</td>\n",
       "      <td>9406251</td>\n",
       "      <td>7.907741e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093121</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHOKA</td>\n",
       "      <td>112.80</td>\n",
       "      <td>123.30</td>\n",
       "      <td>111.80</td>\n",
       "      <td>112.15</td>\n",
       "      <td>123.1</td>\n",
       "      <td>10.95</td>\n",
       "      <td>9.76</td>\n",
       "      <td>17716622</td>\n",
       "      <td>2.112353e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>0.008387</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>TIINDIA</td>\n",
       "      <td>3040.00</td>\n",
       "      <td>3100.30</td>\n",
       "      <td>2905.00</td>\n",
       "      <td>3103.80</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>-118.80</td>\n",
       "      <td>-3.83</td>\n",
       "      <td>1312908</td>\n",
       "      <td>3.898444e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038276</td>\n",
       "      <td>0.102743</td>\n",
       "      <td>890.042857</td>\n",
       "      <td>1366.771667</td>\n",
       "      <td>1478.040</td>\n",
       "      <td>1980.48650</td>\n",
       "      <td>57.494902</td>\n",
       "      <td>0.065427</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>TATAINVEST</td>\n",
       "      <td>3437.95</td>\n",
       "      <td>3475.00</td>\n",
       "      <td>3245.55</td>\n",
       "      <td>3440.60</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>-160.60</td>\n",
       "      <td>-4.67</td>\n",
       "      <td>692221</td>\n",
       "      <td>2.307041e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046678</td>\n",
       "      <td>0.127416</td>\n",
       "      <td>1326.714286</td>\n",
       "      <td>1452.638333</td>\n",
       "      <td>1525.489</td>\n",
       "      <td>1984.97675</td>\n",
       "      <td>58.385272</td>\n",
       "      <td>0.069954</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>HNDFDS</td>\n",
       "      <td>573.85</td>\n",
       "      <td>574.05</td>\n",
       "      <td>531.55</td>\n",
       "      <td>568.40</td>\n",
       "      <td>537.0</td>\n",
       "      <td>-31.40</td>\n",
       "      <td>-5.52</td>\n",
       "      <td>457467</td>\n",
       "      <td>2.487706e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055243</td>\n",
       "      <td>0.163238</td>\n",
       "      <td>1328.064286</td>\n",
       "      <td>1444.571667</td>\n",
       "      <td>1526.159</td>\n",
       "      <td>1973.34650</td>\n",
       "      <td>50.373904</td>\n",
       "      <td>0.079143</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>FINCABLES</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>1216.25</td>\n",
       "      <td>1110.50</td>\n",
       "      <td>1195.55</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>-79.55</td>\n",
       "      <td>-6.65</td>\n",
       "      <td>1117926</td>\n",
       "      <td>1.289584e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066538</td>\n",
       "      <td>0.213084</td>\n",
       "      <td>1336.721429</td>\n",
       "      <td>1287.271667</td>\n",
       "      <td>1542.129</td>\n",
       "      <td>1972.30250</td>\n",
       "      <td>52.329102</td>\n",
       "      <td>0.094758</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>Medium Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>NAVINFLUOR</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>4000.05</td>\n",
       "      <td>3726.65</td>\n",
       "      <td>4357.65</td>\n",
       "      <td>3764.0</td>\n",
       "      <td>-593.65</td>\n",
       "      <td>-13.62</td>\n",
       "      <td>3246796</td>\n",
       "      <td>1.231825e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136232</td>\n",
       "      <td>0.431962</td>\n",
       "      <td>1807.657143</td>\n",
       "      <td>1347.038333</td>\n",
       "      <td>1607.715</td>\n",
       "      <td>1990.68150</td>\n",
       "      <td>53.228897</td>\n",
       "      <td>0.072635</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>High Risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SYMBOL     OPEN     HIGH      LOW  PREV. CLOSE     LTP  \\\n",
       "0    NIFTY TOTAL MARKET  9666.80  9737.90  9653.75      9633.95  9702.5   \n",
       "1             EDELWEISS    54.50    62.55    54.25        54.10    61.6   \n",
       "2               GMDCLTD   284.35   323.85   284.00       282.95   315.8   \n",
       "3              GLENMARK   783.75   861.70   782.10       776.95   854.8   \n",
       "4                ASHOKA   112.80   123.30   111.80       112.15   123.1   \n",
       "..                  ...      ...      ...      ...          ...     ...   \n",
       "747             TIINDIA  3040.00  3100.30  2905.00      3103.80  2985.0   \n",
       "748          TATAINVEST  3437.95  3475.00  3245.55      3440.60  3280.0   \n",
       "749              HNDFDS   573.85   574.05   531.55       568.40   537.0   \n",
       "750           FINCABLES  1200.00  1216.25  1110.50      1195.55  1116.0   \n",
       "751          NAVINFLUOR  4000.00  4000.05  3726.65      4357.65  3764.0   \n",
       "\n",
       "       CHNG  %CHNG  VOLUME \\n(shares)         VALUE  ...  Daily Return  \\\n",
       "0     68.55   0.71         2649691885  6.231052e+11  ...      0.007115   \n",
       "1      7.50  13.86           45507201  2.681739e+09  ...      0.138632   \n",
       "2     32.85  11.61           23800714  7.378697e+09  ...      0.116098   \n",
       "3     77.85  10.02            9406251  7.907741e+09  ...      0.100199   \n",
       "4     10.95   9.76           17716622  2.112353e+09  ...      0.097637   \n",
       "..      ...    ...                ...           ...  ...           ...   \n",
       "747 -118.80  -3.83            1312908  3.898444e+09  ...     -0.038276   \n",
       "748 -160.60  -4.67             692221  2.307041e+09  ...     -0.046678   \n",
       "749  -31.40  -5.52             457467  2.487706e+08  ...     -0.055243   \n",
       "750  -79.55  -6.65            1117926  1.289584e+09  ...     -0.066538   \n",
       "751 -593.65 -13.62            3246796  1.231825e+10  ...     -0.136232   \n",
       "\n",
       "     Volatility     7-Day MA    30-Day MA  50-Day MA  200-Day MA        RSI  \\\n",
       "0      0.000000     0.000000     0.000000      0.000     0.00000   0.000000   \n",
       "1      0.000000     0.000000     0.000000      0.000     0.00000   0.000000   \n",
       "2      0.000000     0.000000     0.000000      0.000     0.00000   0.000000   \n",
       "3      0.000000     0.000000     0.000000      0.000     0.00000   0.000000   \n",
       "4      0.000000     0.000000     0.000000      0.000     0.00000   0.000000   \n",
       "..          ...          ...          ...        ...         ...        ...   \n",
       "747    0.102743   890.042857  1366.771667   1478.040  1980.48650  57.494902   \n",
       "748    0.127416  1326.714286  1452.638333   1525.489  1984.97675  58.385272   \n",
       "749    0.163238  1328.064286  1444.571667   1526.159  1973.34650  50.373904   \n",
       "750    0.213084  1336.721429  1287.271667   1542.129  1972.30250  52.329102   \n",
       "751    0.431962  1807.657143  1347.038333   1607.715  1990.68150  53.228897   \n",
       "\n",
       "     Bid-Ask Spread  Volume Ratio  Risk Category  \n",
       "0          0.008673      0.004252       Low Risk  \n",
       "1          0.134740      0.016969       Low Risk  \n",
       "2          0.126187      0.003226       Low Risk  \n",
       "3          0.093121      0.001189       Low Risk  \n",
       "4          0.093420      0.008387       Low Risk  \n",
       "..              ...           ...            ...  \n",
       "747        0.065427      0.000337       Low Risk  \n",
       "748        0.069954      0.000300       Low Risk  \n",
       "749        0.079143      0.001839       Low Risk  \n",
       "750        0.094758      0.000867    Medium Risk  \n",
       "751        0.072635      0.000264      High Risk  \n",
       "\n",
       "[752 rows x 24 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Risk Category\n",
       "Low Risk       743\n",
       "High Risk        5\n",
       "Medium Risk      4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Risk Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['VOLUME \\n(shares)', 'VALUE', 'SYMBOL', 'Risk Category']\n",
    "\n",
    "# Drop the specified columns\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OPEN', 'HIGH', 'LOW', 'PREV. CLOSE', 'LTP', 'CHNG', '%CHNG', '52W H',\n",
       "       '52W L', '30 D   %CHNG', '365 D % CHNG \\n 29-Sep-2022', 'Daily Return',\n",
       "       'Volatility', '7-Day MA', '30-Day MA', '50-Day MA', '200-Day MA', 'RSI',\n",
       "       'Bid-Ask Spread', 'Volume Ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 \n",
    "### Where no parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['OPEN', 'HIGH', 'LOW', 'PREV. CLOSE', 'CHNG', '%CHNG', '52W H',\n",
    "       '52W L', '30 D   %CHNG', '365 D % CHNG \\n 29-Sep-2022', 'Daily Return',\n",
    "       'Volatility','Bid-Ask Spread', 'Volume Ratio']]\n",
    "y=df['LTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((601, 14), (151, 14))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    # mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true,predicted))\n",
    "    r2_square = r2_score(true,predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 19.1866\n",
      "- Mean Absolute Error: 6.4128\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 25.8192\n",
      "- Mean Absolute Error: 6.2046\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0003\n",
      "- Mean Absolute Error: 0.0001\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0014\n",
      "- Mean Absolute Error: 0.0002\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 2668.3464\n",
      "- Mean Absolute Error: 168.0521\n",
      "- R2 Score: 0.7399\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 1167.8033\n",
      "- Mean Absolute Error: 153.5482\n",
      "- R2 Score: 0.9200\n",
      "=============================================\n",
      "\n",
      "\n",
      "Support Vector Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5308.5564\n",
      "- Mean Absolute Error: 1259.5613\n",
      "- R2 Score: -0.0295\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 4209.9712\n",
      "- Mean Absolute Error: 1156.8359\n",
      "- R2 Score: -0.0398\n",
      "=============================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 713.0988\n",
      "- Mean Absolute Error: 81.2265\n",
      "- R2 Score: 0.9702\n",
      "=============================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 1261.2204\n",
      "- Mean Absolute Error: 74.0257\n",
      "- R2 Score: 0.9419\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 663.1038\n",
      "- Mean Absolute Error: 93.2810\n",
      "- R2 Score: 0.9742\n",
      "=============================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 1.1088\n",
      "- Mean Absolute Error: 0.7781\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 520.8157\n",
      "- Mean Absolute Error: 66.5582\n",
      "- R2 Score: 0.9841\n",
      "=============================================\n",
      "\n",
      "\n",
      "CatBoosting Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 22.7007\n",
      "- Mean Absolute Error: 17.9697\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 710.8781\n",
      "- Mean Absolute Error: 123.2232\n",
      "- R2 Score: 0.9704\n",
      "=============================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 486.7657\n",
      "- Mean Absolute Error: 404.4956\n",
      "- R2 Score: 0.9913\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 772.1811\n",
      "- Mean Absolute Error: 452.4830\n",
      "- R2 Score: 0.9650\n",
      "=============================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}\n",
    "model_list = []\n",
    "r2_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evalute Train and test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*45)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy of the model is 100.00\n"
     ]
    }
   ],
   "source": [
    "lin_model = LinearRegression(fit_intercept=True)\n",
    "lin_model = lin_model.fit(X_train, y_train)\n",
    "y_pred = lin_model.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)*100\n",
    "print(\" Accuracy of the model is %.2f\" %score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predicted')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test,y_pred)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='LTP'>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x=y_test,y=y_pred,ci=None,color ='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Value</th>\n",
       "      <th>Predicted value</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>674.00</td>\n",
       "      <td>674.00</td>\n",
       "      <td>-9.094947e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>1029.00</td>\n",
       "      <td>1029.00</td>\n",
       "      <td>-4.547474e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>907.45</td>\n",
       "      <td>907.45</td>\n",
       "      <td>-7.958079e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1234.00</td>\n",
       "      <td>1234.00</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>138.60</td>\n",
       "      <td>138.60</td>\n",
       "      <td>-1.676881e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>17.75</td>\n",
       "      <td>17.75</td>\n",
       "      <td>-2.099654e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>563.00</td>\n",
       "      <td>563.00</td>\n",
       "      <td>-7.958079e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>222.00</td>\n",
       "      <td>222.00</td>\n",
       "      <td>-1.506351e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>278.05</td>\n",
       "      <td>278.05</td>\n",
       "      <td>-1.591616e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>233.40</td>\n",
       "      <td>233.40</td>\n",
       "      <td>-1.108447e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual Value  Predicted value    Difference\n",
       "584        674.00           674.00 -9.094947e-13\n",
       "591       1029.00          1029.00 -4.547474e-13\n",
       "486        907.45           907.45 -7.958079e-13\n",
       "77        1234.00          1234.00 -2.273737e-13\n",
       "212        138.60           138.60 -1.676881e-12\n",
       "..            ...              ...           ...\n",
       "331         17.75            17.75 -2.099654e-12\n",
       "90         563.00           563.00 -7.958079e-13\n",
       "355        222.00           222.00 -1.506351e-12\n",
       "497        278.05           278.05 -1.591616e-12\n",
       "69         233.40           233.40 -1.108447e-12\n",
       "\n",
       "[151 rows x 3 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df=pd.DataFrame({'Actual Value':y_test,'Predicted value':y_pred,'Difference':y_test-y_pred})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy of the model is 95.96\n"
     ]
    }
   ],
   "source": [
    "randomforest_model = RandomForestRegressor()\n",
    "randomforest_model = randomforest_model.fit(X_train, y_train)\n",
    "y_pred = randomforest_model.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)*100\n",
    "print(\" Accuracy of the model is %.2f\" %score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predicted')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test,y_pred)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='LTP'>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x=y_test,y=y_pred,ci=None,color ='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Value</th>\n",
       "      <th>Predicted value</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>674.00</td>\n",
       "      <td>682.1575</td>\n",
       "      <td>-8.1575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>1029.00</td>\n",
       "      <td>1032.3970</td>\n",
       "      <td>-3.3970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>907.45</td>\n",
       "      <td>912.5760</td>\n",
       "      <td>-5.1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1234.00</td>\n",
       "      <td>1216.4740</td>\n",
       "      <td>17.5260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>138.60</td>\n",
       "      <td>137.7530</td>\n",
       "      <td>0.8470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>17.75</td>\n",
       "      <td>18.2950</td>\n",
       "      <td>-0.5450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>563.00</td>\n",
       "      <td>558.7990</td>\n",
       "      <td>4.2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>222.00</td>\n",
       "      <td>222.5675</td>\n",
       "      <td>-0.5675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>278.05</td>\n",
       "      <td>281.7290</td>\n",
       "      <td>-3.6790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>233.40</td>\n",
       "      <td>230.3665</td>\n",
       "      <td>3.0335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual Value  Predicted value  Difference\n",
       "584        674.00         682.1575     -8.1575\n",
       "591       1029.00        1032.3970     -3.3970\n",
       "486        907.45         912.5760     -5.1260\n",
       "77        1234.00        1216.4740     17.5260\n",
       "212        138.60         137.7530      0.8470\n",
       "..            ...              ...         ...\n",
       "331         17.75          18.2950     -0.5450\n",
       "90         563.00         558.7990      4.2010\n",
       "355        222.00         222.5675     -0.5675\n",
       "497        278.05         281.7290     -3.6790\n",
       "69         233.40         230.3665      3.0335\n",
       "\n",
       "[151 rows x 3 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred_df=pd.DataFrame({'Actual Value':y_test,'Predicted value':y_pred,'Difference':y_test-y_pred})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 \n",
    "## Where only 7-Day and RSI is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['OPEN', 'HIGH', 'LOW', 'PREV. CLOSE', 'CHNG', '%CHNG', '52W H',\n",
    "       '52W L', '30 D   %CHNG', '365 D % CHNG \\n 29-Sep-2022', 'Daily Return',\n",
    "       'Volatility', '7-Day MA', 'RSI',\n",
    "       'Bid-Ask Spread', 'Volume Ratio']]\n",
    "y=df['LTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((601, 16), (151, 16))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    # mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true,predicted))\n",
    "    r2_square = r2_score(true,predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 19.0296\n",
      "- Mean Absolute Error: 6.5735\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 26.4441\n",
      "- Mean Absolute Error: 6.4172\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0003\n",
      "- Mean Absolute Error: 0.0001\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0014\n",
      "- Mean Absolute Error: 0.0003\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 2669.1059\n",
      "- Mean Absolute Error: 183.9752\n",
      "- R2 Score: 0.7397\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 1170.1253\n",
      "- Mean Absolute Error: 170.9957\n",
      "- R2 Score: 0.9197\n",
      "=============================================\n",
      "\n",
      "\n",
      "Support Vector Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5311.4396\n",
      "- Mean Absolute Error: 1260.2109\n",
      "- R2 Score: -0.0306\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 4213.2619\n",
      "- Mean Absolute Error: 1157.8144\n",
      "- R2 Score: -0.0414\n",
      "=============================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 522.9658\n",
      "- Mean Absolute Error: 67.3291\n",
      "- R2 Score: 0.9840\n",
      "=============================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 1071.1509\n",
      "- Mean Absolute Error: 59.3006\n",
      "- R2 Score: 0.9581\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 765.7089\n",
      "- Mean Absolute Error: 107.8562\n",
      "- R2 Score: 0.9656\n",
      "=============================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.9024\n",
      "- Mean Absolute Error: 0.6176\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 559.8462\n",
      "- Mean Absolute Error: 73.9246\n",
      "- R2 Score: 0.9816\n",
      "=============================================\n",
      "\n",
      "\n",
      "CatBoosting Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 22.5079\n",
      "- Mean Absolute Error: 17.8951\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 987.8807\n",
      "- Mean Absolute Error: 170.6410\n",
      "- R2 Score: 0.9427\n",
      "=============================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 448.6746\n",
      "- Mean Absolute Error: 370.6692\n",
      "- R2 Score: 0.9926\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 847.1783\n",
      "- Mean Absolute Error: 441.5540\n",
      "- R2 Score: 0.9579\n",
      "=============================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}\n",
    "model_list = []\n",
    "r2_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evalute Train and test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*45)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3\n",
    "## Where 30 D MA and Rsi used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['OPEN', 'HIGH', 'LOW', 'PREV. CLOSE', 'CHNG', '%CHNG', '52W H',\n",
    "       '52W L', '30 D   %CHNG', '365 D % CHNG \\n 29-Sep-2022', 'Daily Return',\n",
    "       'Volatility', '30-Day MA', 'RSI',\n",
    "       'Bid-Ask Spread', 'Volume Ratio']]\n",
    "y=df['LTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((601, 16), (151, 16))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    # mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true,predicted))\n",
    "    r2_square = r2_score(true,predicted)\n",
    "    return mae, rmse, r2_square\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 18.8633\n",
      "- Mean Absolute Error: 7.0275\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 26.4690\n",
      "- Mean Absolute Error: 7.3626\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0003\n",
      "- Mean Absolute Error: 0.0001\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0014\n",
      "- Mean Absolute Error: 0.0003\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 2668.4328\n",
      "- Mean Absolute Error: 177.6377\n",
      "- R2 Score: 0.7399\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 1168.6700\n",
      "- Mean Absolute Error: 170.2466\n",
      "- R2 Score: 0.9199\n",
      "=============================================\n",
      "\n",
      "\n",
      "Support Vector Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5308.6632\n",
      "- Mean Absolute Error: 1259.8031\n",
      "- R2 Score: -0.0295\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 4210.0791\n",
      "- Mean Absolute Error: 1157.0241\n",
      "- R2 Score: -0.0399\n",
      "=============================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 764.5443\n",
      "- Mean Absolute Error: 85.8195\n",
      "- R2 Score: 0.9657\n",
      "=============================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 1020.0054\n",
      "- Mean Absolute Error: 62.1929\n",
      "- R2 Score: 0.9620\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 491.2248\n",
      "- Mean Absolute Error: 73.4478\n",
      "- R2 Score: 0.9858\n",
      "=============================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.7682\n",
      "- Mean Absolute Error: 0.5588\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 521.3400\n",
      "- Mean Absolute Error: 67.3018\n",
      "- R2 Score: 0.9841\n",
      "=============================================\n",
      "\n",
      "\n",
      "CatBoosting Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 23.8881\n",
      "- Mean Absolute Error: 19.2559\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 896.5529\n",
      "- Mean Absolute Error: 163.8888\n",
      "- R2 Score: 0.9528\n",
      "=============================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 546.2365\n",
      "- Mean Absolute Error: 458.5331\n",
      "- R2 Score: 0.9891\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 874.6166\n",
      "- Mean Absolute Error: 489.4090\n",
      "- R2 Score: 0.9551\n",
      "=============================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}\n",
    "model_list = []\n",
    "r2_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evalute Train and test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*45)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4\n",
    "## Where 50 D MA and Rsi used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=df[['OPEN', 'HIGH', 'LOW', 'PREV. CLOSE', 'CHNG', '%CHNG', '52W H',\n",
    "       '52W L', '30 D   %CHNG', '365 D % CHNG \\n 29-Sep-2022', 'Daily Return',\n",
    "       'Volatility', '50-Day MA', 'RSI',\n",
    "       'Bid-Ask Spread', 'Volume Ratio']]\n",
    "y=df['LTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((601, 16), (151, 16))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X1_train, X1_test, y_train, y_test = train_test_split(X1,y,test_size=0.2,random_state=42)\n",
    "X1_train.shape, X1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    # mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true,predicted))\n",
    "    r2_square = r2_score(true,predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 18.8241\n",
      "- Mean Absolute Error: 7.0787\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 26.7188\n",
      "- Mean Absolute Error: 7.2015\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0003\n",
      "- Mean Absolute Error: 0.0001\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0015\n",
      "- Mean Absolute Error: 0.0003\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 2668.5041\n",
      "- Mean Absolute Error: 177.9333\n",
      "- R2 Score: 0.7399\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 1168.3451\n",
      "- Mean Absolute Error: 166.3106\n",
      "- R2 Score: 0.9199\n",
      "=============================================\n",
      "\n",
      "\n",
      "Support Vector Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5308.6627\n",
      "- Mean Absolute Error: 1259.7855\n",
      "- R2 Score: -0.0295\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 4210.0771\n",
      "- Mean Absolute Error: 1157.0305\n",
      "- R2 Score: -0.0399\n",
      "=============================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 764.4795\n",
      "- Mean Absolute Error: 85.1778\n",
      "- R2 Score: 0.9657\n",
      "=============================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 1148.4207\n",
      "- Mean Absolute Error: 67.8128\n",
      "- R2 Score: 0.9518\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 422.4957\n",
      "- Mean Absolute Error: 68.1041\n",
      "- R2 Score: 0.9895\n",
      "=============================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.9247\n",
      "- Mean Absolute Error: 0.6482\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 519.4030\n",
      "- Mean Absolute Error: 66.2390\n",
      "- R2 Score: 0.9842\n",
      "=============================================\n",
      "\n",
      "\n",
      "CatBoosting Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 21.3228\n",
      "- Mean Absolute Error: 17.1371\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 1024.9003\n",
      "- Mean Absolute Error: 172.7789\n",
      "- R2 Score: 0.9384\n",
      "=============================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 616.1961\n",
      "- Mean Absolute Error: 535.2265\n",
      "- R2 Score: 0.9861\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 834.7066\n",
      "- Mean Absolute Error: 551.0834\n",
      "- R2 Score: 0.9591\n",
      "=============================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}\n",
    "model_list = []\n",
    "r2_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X1_train,y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X1_train)\n",
    "    y_test_pred = model.predict(X1_test)\n",
    "\n",
    "    # Evalute Train and test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*45)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5\n",
    "## Where 200 Ma and RSI is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['OPEN', 'HIGH', 'LOW', 'PREV. CLOSE', 'CHNG', '%CHNG', '52W H',\n",
    "       '52W L', '30 D   %CHNG', '365 D % CHNG \\n 29-Sep-2022', 'Daily Return',\n",
    "       'Volatility','200-Day MA', 'RSI',\n",
    "       'Bid-Ask Spread', 'Volume Ratio']]\n",
    "y=df['LTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((601, 16), (151, 16))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    # mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true,predicted))\n",
    "    r2_square = r2_score(true,predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 18.5820\n",
      "- Mean Absolute Error: 7.2959\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 25.8103\n",
      "- Mean Absolute Error: 7.0966\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0003\n",
      "- Mean Absolute Error: 0.0001\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0014\n",
      "- Mean Absolute Error: 0.0003\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 2668.4477\n",
      "- Mean Absolute Error: 173.2437\n",
      "- R2 Score: 0.7399\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 1168.1238\n",
      "- Mean Absolute Error: 159.4359\n",
      "- R2 Score: 0.9199\n",
      "=============================================\n",
      "\n",
      "\n",
      "Support Vector Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5308.6629\n",
      "- Mean Absolute Error: 1259.7186\n",
      "- R2 Score: -0.0295\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 4210.0954\n",
      "- Mean Absolute Error: 1156.9903\n",
      "- R2 Score: -0.0399\n",
      "=============================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 522.0884\n",
      "- Mean Absolute Error: 65.0351\n",
      "- R2 Score: 0.9840\n",
      "=============================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 1261.8011\n",
      "- Mean Absolute Error: 66.6012\n",
      "- R2 Score: 0.9418\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 648.6558\n",
      "- Mean Absolute Error: 90.9507\n",
      "- R2 Score: 0.9753\n",
      "=============================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.8633\n",
      "- Mean Absolute Error: 0.6272\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 518.9708\n",
      "- Mean Absolute Error: 65.0993\n",
      "- R2 Score: 0.9842\n",
      "=============================================\n",
      "\n",
      "\n",
      "CatBoosting Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 23.2677\n",
      "- Mean Absolute Error: 18.5790\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 1009.1949\n",
      "- Mean Absolute Error: 181.1279\n",
      "- R2 Score: 0.9402\n",
      "=============================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 425.9762\n",
      "- Mean Absolute Error: 359.6355\n",
      "- R2 Score: 0.9934\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 712.9740\n",
      "- Mean Absolute Error: 407.9515\n",
      "- R2 Score: 0.9702\n",
      "=============================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}\n",
    "model_list = []\n",
    "r2_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evalute Train and test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*45)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6\n",
    "## Where Rsi is only used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['OPEN', 'HIGH', 'LOW', 'PREV. CLOSE', 'CHNG', '%CHNG', '52W H',\n",
    "       '52W L', '30 D   %CHNG', '365 D % CHNG \\n 29-Sep-2022', 'Daily Return',\n",
    "       'Volatility', 'RSI',\n",
    "       'Bid-Ask Spread', 'Volume Ratio']]\n",
    "y=df['LTP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((601, 15), (151, 15))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    # mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true,predicted))\n",
    "    r2_square = r2_score(true,predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 19.0326\n",
      "- Mean Absolute Error: 6.5769\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 26.4568\n",
      "- Mean Absolute Error: 6.3715\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0003\n",
      "- Mean Absolute Error: 0.0001\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0014\n",
      "- Mean Absolute Error: 0.0002\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 2668.3461\n",
      "- Mean Absolute Error: 168.1015\n",
      "- R2 Score: 0.7399\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 1167.8047\n",
      "- Mean Absolute Error: 153.7419\n",
      "- R2 Score: 0.9200\n",
      "=============================================\n",
      "\n",
      "\n",
      "Support Vector Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5308.5687\n",
      "- Mean Absolute Error: 1259.5876\n",
      "- R2 Score: -0.0295\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 4209.9851\n",
      "- Mean Absolute Error: 1156.8610\n",
      "- R2 Score: -0.0398\n",
      "=============================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 764.9575\n",
      "- Mean Absolute Error: 88.8139\n",
      "- R2 Score: 0.9657\n",
      "=============================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 1344.0935\n",
      "- Mean Absolute Error: 69.5420\n",
      "- R2 Score: 0.9340\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 603.6706\n",
      "- Mean Absolute Error: 87.7167\n",
      "- R2 Score: 0.9786\n",
      "=============================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 1.0478\n",
      "- Mean Absolute Error: 0.7409\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 518.6369\n",
      "- Mean Absolute Error: 66.3197\n",
      "- R2 Score: 0.9842\n",
      "=============================================\n",
      "\n",
      "\n",
      "CatBoosting Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 24.5214\n",
      "- Mean Absolute Error: 19.3401\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 1013.2485\n",
      "- Mean Absolute Error: 168.1356\n",
      "- R2 Score: 0.9398\n",
      "=============================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 703.4812\n",
      "- Mean Absolute Error: 632.0665\n",
      "- R2 Score: 0.9819\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 918.6883\n",
      "- Mean Absolute Error: 653.9765\n",
      "- R2 Score: 0.9505\n",
      "=============================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}\n",
    "model_list = []\n",
    "r2_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evalute Train and test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*45)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 7\n",
    "## Where only 7 D ma is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['OPEN', 'HIGH', 'LOW', 'PREV. CLOSE', 'CHNG', '%CHNG', '52W H',\n",
    "       '52W L', '30 D   %CHNG', '365 D % CHNG \\n 29-Sep-2022', 'Daily Return',\n",
    "       'Volatility', '7-Day MA',\n",
    "       'Bid-Ask Spread', 'Volume Ratio']]\n",
    "y=df['LTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((601, 15), (151, 15))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    # mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true,predicted))\n",
    "    r2_square = r2_score(true,predicted)\n",
    "    return mae, rmse, r2_square\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 19.1745\n",
      "- Mean Absolute Error: 6.4056\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 25.8626\n",
      "- Mean Absolute Error: 6.2593\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0003\n",
      "- Mean Absolute Error: 0.0001\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0014\n",
      "- Mean Absolute Error: 0.0002\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 2669.1064\n",
      "- Mean Absolute Error: 183.9828\n",
      "- R2 Score: 0.7397\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 1170.1258\n",
      "- Mean Absolute Error: 170.9085\n",
      "- R2 Score: 0.9197\n",
      "=============================================\n",
      "\n",
      "\n",
      "Support Vector Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5311.4253\n",
      "- Mean Absolute Error: 1260.1816\n",
      "- R2 Score: -0.0306\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 4213.2457\n",
      "- Mean Absolute Error: 1157.7860\n",
      "- R2 Score: -0.0414\n",
      "=============================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 521.9106\n",
      "- Mean Absolute Error: 62.7742\n",
      "- R2 Score: 0.9840\n",
      "=============================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 1284.0198\n",
      "- Mean Absolute Error: 72.9209\n",
      "- R2 Score: 0.9398\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 444.8733\n",
      "- Mean Absolute Error: 63.0375\n",
      "- R2 Score: 0.9884\n",
      "=============================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.9640\n",
      "- Mean Absolute Error: 0.6784\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 559.7222\n",
      "- Mean Absolute Error: 74.2548\n",
      "- R2 Score: 0.9816\n",
      "=============================================\n",
      "\n",
      "\n",
      "CatBoosting Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 26.5127\n",
      "- Mean Absolute Error: 20.7568\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 639.6665\n",
      "- Mean Absolute Error: 125.6316\n",
      "- R2 Score: 0.9760\n",
      "=============================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 695.1783\n",
      "- Mean Absolute Error: 617.8255\n",
      "- R2 Score: 0.9823\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 883.2211\n",
      "- Mean Absolute Error: 612.0516\n",
      "- R2 Score: 0.9542\n",
      "=============================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}\n",
    "model_list = []\n",
    "r2_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train) # Train model\n",
    "\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evalute Train and test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*45)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 8 \n",
    "## where only 30 D is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['OPEN', 'HIGH', 'LOW', 'PREV. CLOSE', 'CHNG', '%CHNG', '52W H',\n",
    "       '52W L', '30 D   %CHNG', '365 D % CHNG \\n 29-Sep-2022', 'Daily Return',\n",
    "       'Volatility', '30-Day MA',\n",
    "       'Bid-Ask Spread', 'Volume Ratio']]\n",
    "y=df['LTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((601, 15), (151, 15))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    # mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true,predicted))\n",
    "    r2_square = r2_score(true,predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 19.0066\n",
      "- Mean Absolute Error: 6.8454\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 25.9843\n",
      "- Mean Absolute Error: 7.2168\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0003\n",
      "- Mean Absolute Error: 0.0001\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0014\n",
      "- Mean Absolute Error: 0.0003\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 2668.4329\n",
      "- Mean Absolute Error: 177.6470\n",
      "- R2 Score: 0.7399\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 1168.6700\n",
      "- Mean Absolute Error: 170.2427\n",
      "- R2 Score: 0.9199\n",
      "=============================================\n",
      "\n",
      "\n",
      "Support Vector Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5308.6488\n",
      "- Mean Absolute Error: 1259.7726\n",
      "- R2 Score: -0.0295\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 4210.0629\n",
      "- Mean Absolute Error: 1156.9948\n",
      "- R2 Score: -0.0399\n",
      "=============================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 764.0787\n",
      "- Mean Absolute Error: 84.0881\n",
      "- R2 Score: 0.9657\n",
      "=============================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 1122.9233\n",
      "- Mean Absolute Error: 67.4800\n",
      "- R2 Score: 0.9539\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 506.8936\n",
      "- Mean Absolute Error: 72.0342\n",
      "- R2 Score: 0.9849\n",
      "=============================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 1.0246\n",
      "- Mean Absolute Error: 0.7038\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 520.4995\n",
      "- Mean Absolute Error: 67.3623\n",
      "- R2 Score: 0.9841\n",
      "=============================================\n",
      "\n",
      "\n",
      "CatBoosting Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 24.3259\n",
      "- Mean Absolute Error: 19.4359\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 682.5966\n",
      "- Mean Absolute Error: 125.3245\n",
      "- R2 Score: 0.9727\n",
      "=============================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 375.6722\n",
      "- Mean Absolute Error: 303.5745\n",
      "- R2 Score: 0.9948\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 719.1562\n",
      "- Mean Absolute Error: 356.4440\n",
      "- R2 Score: 0.9697\n",
      "=============================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}\n",
    "model_list = []\n",
    "r2_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train) # Train model\n",
    "\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\t\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evalute Train and test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*45)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 9\n",
    "## Where 50 D is only used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['OPEN', 'HIGH', 'LOW', 'PREV. CLOSE', 'CHNG', '%CHNG', '52W H',\n",
    "       '52W L', '30 D   %CHNG', '365 D % CHNG \\n 29-Sep-2022', 'Daily Return',\n",
    "       'Volatility', '50-Day MA',\n",
    "       'Bid-Ask Spread', 'Volume Ratio']]\n",
    "y=df['LTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((601, 15), (151, 15))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#  separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    # mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true,predicted))\n",
    "    r2_square = r2_score(true,predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 18.9041\n",
      "- Mean Absolute Error: 6.9199\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 26.6106\n",
      "- Mean Absolute Error: 7.0468\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0003\n",
      "- Mean Absolute Error: 0.0001\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0014\n",
      "- Mean Absolute Error: 0.0003\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 2668.5042\n",
      "- Mean Absolute Error: 177.9490\n",
      "- R2 Score: 0.7399\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 1168.3471\n",
      "- Mean Absolute Error: 166.4437\n",
      "- R2 Score: 0.9199\n",
      "=============================================\n",
      "\n",
      "\n",
      "Support Vector Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5308.6484\n",
      "- Mean Absolute Error: 1259.7549\n",
      "- R2 Score: -0.0295\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 4210.0609\n",
      "- Mean Absolute Error: 1157.0012\n",
      "- R2 Score: -0.0399\n",
      "=============================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 523.2132\n",
      "- Mean Absolute Error: 68.0023\n",
      "- R2 Score: 0.9839\n",
      "=============================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 1231.5134\n",
      "- Mean Absolute Error: 70.1753\n",
      "- R2 Score: 0.9446\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 466.2332\n",
      "- Mean Absolute Error: 68.9313\n",
      "- R2 Score: 0.9872\n",
      "=============================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.8882\n",
      "- Mean Absolute Error: 0.6222\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 520.9932\n",
      "- Mean Absolute Error: 66.1607\n",
      "- R2 Score: 0.9841\n",
      "=============================================\n",
      "\n",
      "\n",
      "CatBoosting Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 23.9574\n",
      "- Mean Absolute Error: 19.1915\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 720.7641\n",
      "- Mean Absolute Error: 136.0664\n",
      "- R2 Score: 0.9695\n",
      "=============================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 420.4374\n",
      "- Mean Absolute Error: 344.6023\n",
      "- R2 Score: 0.9935\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 701.5407\n",
      "- Mean Absolute Error: 367.6290\n",
      "- R2 Score: 0.9711\n",
      "=============================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}\n",
    "model_list = []\n",
    "r2_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train) # Train model\n",
    "\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\t\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evalute Train and test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*45)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 10\n",
    "## Where 200D MA is only used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['OPEN', 'HIGH', 'LOW', 'PREV. CLOSE', 'CHNG', '%CHNG', '52W H',\n",
    "       '52W L', '30 D   %CHNG', '365 D % CHNG \\n 29-Sep-2022', 'Daily Return',\n",
    "       'Volatility', '200-Day MA',\n",
    "       'Bid-Ask Spread', 'Volume Ratio']]\n",
    "y=df['LTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((601, 15), (151, 15))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    # mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true,predicted))\n",
    "    r2_square = r2_score(true,predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 18.6859\n",
      "- Mean Absolute Error: 7.0878\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 25.8357\n",
      "- Mean Absolute Error: 7.1539\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0003\n",
      "- Mean Absolute Error: 0.0001\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.0014\n",
      "- Mean Absolute Error: 0.0002\n",
      "- R2 Score: 1.0000\n",
      "=============================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 2668.4482\n",
      "- Mean Absolute Error: 173.3389\n",
      "- R2 Score: 0.7399\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 1168.1227\n",
      "- Mean Absolute Error: 159.3888\n",
      "- R2 Score: 0.9199\n",
      "=============================================\n",
      "\n",
      "\n",
      "Support Vector Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5308.6496\n",
      "- Mean Absolute Error: 1259.6901\n",
      "- R2 Score: -0.0295\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 4210.0804\n",
      "- Mean Absolute Error: 1156.9631\n",
      "- R2 Score: -0.0399\n",
      "=============================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 523.1623\n",
      "- Mean Absolute Error: 67.4646\n",
      "- R2 Score: 0.9839\n",
      "=============================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 1066.3538\n",
      "- Mean Absolute Error: 66.6040\n",
      "- R2 Score: 0.9585\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 523.4871\n",
      "- Mean Absolute Error: 76.9351\n",
      "- R2 Score: 0.9839\n",
      "=============================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.9086\n",
      "- Mean Absolute Error: 0.6398\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 520.8599\n",
      "- Mean Absolute Error: 65.8372\n",
      "- R2 Score: 0.9841\n",
      "=============================================\n",
      "\n",
      "\n",
      "CatBoosting Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 24.2653\n",
      "- Mean Absolute Error: 19.4592\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 906.5168\n",
      "- Mean Absolute Error: 139.2244\n",
      "- R2 Score: 0.9518\n",
      "=============================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 524.3756\n",
      "- Mean Absolute Error: 435.9246\n",
      "- R2 Score: 0.9900\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 710.5333\n",
      "- Mean Absolute Error: 436.1546\n",
      "- R2 Score: 0.9704\n",
      "=============================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}\n",
    "model_list = []\n",
    "r2_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train) # Train model\n",
    "\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\t\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evalute Train and test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*45)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
